{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Conv2D, Flatten, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tqdm import tqdm\n",
    "import pyaudio\n",
    "import scipy.io.wavfile as wav\n",
    "import os\n",
    "import speechpy\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"CNN\"]\n",
    "dataset_folder = \"/home/vishnu/NN/Data\"\n",
    "class_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happiness\", \"Neutral\", \"Sadness\", \"Surprise\"]\n",
    "mslen = 32000  # Empirically calculated for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(filename):\n",
    "    return wav.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(flatten=True, mfcc_len=39):\n",
    "    data = []\n",
    "    labels = []\n",
    "    max_fs = 0\n",
    "    cnt = 0\n",
    "    cur_dir = os.getcwd()\n",
    "    os.chdir('..')\n",
    "    os.chdir(dataset_folder)\n",
    "    for i, directory in enumerate(class_labels):\n",
    "        print (\"started reading folder\", directory)\n",
    "        os.chdir(directory)\n",
    "        for filename in os.listdir('.'):\n",
    "            fs, signal = read_wav(filename)\n",
    "            max_fs = max(max_fs, fs)\n",
    "            s_len = len(signal)\n",
    "            #Padding the signal to have the same size\n",
    "            if s_len < mslen:\n",
    "                pad_len = mslen - s_len\n",
    "                pad_rem = pad_len % 2\n",
    "                pad_len /= 2\n",
    "                signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "            else:\n",
    "                pad_len = s_len - mslen\n",
    "                pad_rem = pad_len % 2\n",
    "                pad_len /= 2\n",
    "                signal = signal[int(pad_len):int(pad_len) + mslen]\n",
    "            mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=mfcc_len)\n",
    "\n",
    "            if flatten:\n",
    "                # Flatten the data\n",
    "                mfcc = mfcc.flatten()\n",
    "            data.append(mfcc)\n",
    "            labels.append(i)\n",
    "            cnt += 1\n",
    "        print (\"ended reading folder\", directory)\n",
    "        os.chdir('..')\n",
    "    os.chdir(cur_dir)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (13, 13), input_shape=(input_shape[0], input_shape[1], 1)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(8, (13, 13)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Conv2D(8, (13, 13)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(8, (2, 2)))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(class_labels), activation='softmax'))\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started reading folder Angry\n",
      "ended reading folder Angry\n",
      "started reading folder Disgust\n",
      "ended reading folder Disgust\n",
      "started reading folder Fear\n",
      "ended reading folder Fear\n",
      "started reading folder Happiness\n",
      "ended reading folder Happiness\n",
      "started reading folder Neutral\n",
      "ended reading folder Neutral\n",
      "started reading folder Sadness\n",
      "ended reading folder Sadness\n",
      "started reading folder Surprise\n",
      "ended reading folder Surprise\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "global x_train, y_train, x_test, y_test\n",
    "x_train, x_test, y_train, y_test = get_data(flatten=False)\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is CNN so have to reshape the data\n",
    "in_shape = x_train[0].shape\n",
    "x_train = x_train.reshape(x_train.shape[0], in_shape[0], in_shape[1], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], in_shape[0], in_shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(models[0], x_train[0].shape)\n",
    "\n",
    "global best_model_path\n",
    "best_model_path = '/home/vishnu/NN/model_' + models[0] + '.h5'\n",
    "\n",
    "#evaluateModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 58, 27, 8)         1360      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 58, 27, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 58, 27, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 15, 8)         10824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 46, 15, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 3, 8)          10824     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 3, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 3, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 2, 8)          264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 2, 8)          32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 2, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5184      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 29,295\n",
      "Trainable params: 29,103\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 0.4646 - acc: 0.8423 - val_loss: 0.5734 - val_acc: 0.8170\n",
      "Epoch 2/500\n",
      "384/384 [==============================] - 4s 12ms/step - loss: 0.3584 - acc: 0.8635 - val_loss: 0.5928 - val_acc: 0.8125\n",
      "Epoch 3/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.2973 - acc: 0.8802 - val_loss: 0.4710 - val_acc: 0.8438\n",
      "Epoch 4/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.2573 - acc: 0.9014 - val_loss: 0.4172 - val_acc: 0.8527\n",
      "Epoch 5/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.2080 - acc: 0.9174 - val_loss: 0.4235 - val_acc: 0.8497\n",
      "Epoch 6/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.1827 - acc: 0.9297 - val_loss: 0.4236 - val_acc: 0.8452\n",
      "Epoch 7/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.1512 - acc: 0.9498 - val_loss: 0.4264 - val_acc: 0.8393\n",
      "Epoch 8/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.1187 - acc: 0.9665 - val_loss: 0.4383 - val_acc: 0.8393\n",
      "Epoch 9/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.0911 - acc: 0.9799 - val_loss: 0.4357 - val_acc: 0.8408\n",
      "Epoch 10/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.0738 - acc: 0.9881 - val_loss: 0.4431 - val_acc: 0.8348\n",
      "Epoch 11/500\n",
      "384/384 [==============================] - 4s 9ms/step - loss: 0.0657 - acc: 0.9888 - val_loss: 0.4455 - val_acc: 0.8318\n",
      "Epoch 12/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0506 - acc: 0.9955 - val_loss: 0.4730 - val_acc: 0.8259\n",
      "Epoch 13/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0392 - acc: 0.9963 - val_loss: 0.4631 - val_acc: 0.8274\n",
      "Epoch 14/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0343 - acc: 0.9993 - val_loss: 0.4702 - val_acc: 0.8289\n",
      "Epoch 15/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0269 - acc: 0.9989 - val_loss: 0.4731 - val_acc: 0.8244\n",
      "Epoch 16/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0252 - acc: 0.9985 - val_loss: 0.4939 - val_acc: 0.8199\n",
      "Epoch 17/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0210 - acc: 0.9996 - val_loss: 0.4814 - val_acc: 0.8214\n",
      "Epoch 18/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.4772 - val_acc: 0.8125\n",
      "Epoch 19/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0150 - acc: 0.9989 - val_loss: 0.4890 - val_acc: 0.8110\n",
      "Epoch 20/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0120 - acc: 0.9996 - val_loss: 0.5046 - val_acc: 0.8140\n",
      "Epoch 21/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5114 - val_acc: 0.8185\n",
      "Epoch 22/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5010 - val_acc: 0.8199\n",
      "Epoch 23/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0099 - acc: 0.9996 - val_loss: 0.5063 - val_acc: 0.8155\n",
      "Epoch 24/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5086 - val_acc: 0.8155\n",
      "Epoch 25/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5125 - val_acc: 0.8155\n",
      "Epoch 26/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5210 - val_acc: 0.8185\n",
      "Epoch 27/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5275 - val_acc: 0.8185\n",
      "Epoch 28/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5302 - val_acc: 0.8229\n",
      "Epoch 29/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.8199\n",
      "Epoch 30/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5316 - val_acc: 0.8110\n",
      "Epoch 31/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5336 - val_acc: 0.8065\n",
      "Epoch 32/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.8199\n",
      "Epoch 33/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5478 - val_acc: 0.8110\n",
      "Epoch 34/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.8125\n",
      "Epoch 35/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5756 - val_acc: 0.8155\n",
      "Epoch 36/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5872 - val_acc: 0.8110\n",
      "Epoch 37/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.8125\n",
      "Epoch 38/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.8080\n",
      "Epoch 39/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5709 - val_acc: 0.8080\n",
      "Epoch 40/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.8095\n",
      "Epoch 41/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0035 - acc: 0.9996 - val_loss: 0.5799 - val_acc: 0.8155\n",
      "Epoch 42/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.8259\n",
      "Epoch 43/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5681 - val_acc: 0.8185\n",
      "Epoch 44/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5617 - val_acc: 0.8110\n",
      "Epoch 45/500\n",
      "384/384 [==============================] - 4s 12ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.5615 - val_acc: 0.8170\n",
      "Epoch 46/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5854 - val_acc: 0.8140\n",
      "Epoch 47/500\n",
      "384/384 [==============================] - 5s 14ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5899 - val_acc: 0.8155\n",
      "Epoch 48/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.8036\n",
      "Epoch 49/500\n",
      "384/384 [==============================] - 7s 18ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.7917\n",
      "Epoch 50/500\n",
      "384/384 [==============================] - 5s 14ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7976\n",
      "Epoch 51/500\n",
      "384/384 [==============================] - 5s 14ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5906 - val_acc: 0.8036\n",
      "Epoch 52/500\n",
      "384/384 [==============================] - 5s 14ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.8110\n",
      "Epoch 53/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.8065\n",
      "Epoch 54/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5867 - val_acc: 0.8080\n",
      "Epoch 55/500\n",
      "384/384 [==============================] - 5s 14ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5902 - val_acc: 0.8065\n",
      "Epoch 56/500\n",
      "384/384 [==============================] - 4s 12ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5906 - val_acc: 0.8125\n",
      "Epoch 57/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6073 - val_acc: 0.8140\n",
      "Epoch 58/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5878 - val_acc: 0.8095\n",
      "Epoch 59/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 0.5896 - val_acc: 0.8036\n",
      "Epoch 60/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5874 - val_acc: 0.8036\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5998 - val_acc: 0.8095\n",
      "Epoch 62/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.8140\n",
      "Epoch 63/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.8170\n",
      "Epoch 64/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6161 - val_acc: 0.8036\n",
      "Epoch 65/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6204 - val_acc: 0.8095\n",
      "Epoch 66/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6229 - val_acc: 0.8036\n",
      "Epoch 67/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5964 - val_acc: 0.8036\n",
      "Epoch 68/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5910 - val_acc: 0.8006\n",
      "Epoch 69/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5986 - val_acc: 0.7991\n",
      "Epoch 70/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.8051\n",
      "Epoch 71/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6025 - val_acc: 0.8036\n",
      "Epoch 72/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.8065\n",
      "Epoch 73/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.8051\n",
      "Epoch 74/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6308 - val_acc: 0.8036\n",
      "Epoch 75/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 0.8051\n",
      "Epoch 76/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 8.1860e-04 - acc: 1.0000 - val_loss: 0.6587 - val_acc: 0.8080\n",
      "Epoch 77/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.4058e-04 - acc: 1.0000 - val_loss: 0.6442 - val_acc: 0.8051\n",
      "Epoch 78/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6291 - val_acc: 0.7961\n",
      "Epoch 79/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 8.4017e-04 - acc: 1.0000 - val_loss: 0.6243 - val_acc: 0.7976\n",
      "Epoch 80/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.7917\n",
      "Epoch 81/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.2168e-04 - acc: 1.0000 - val_loss: 0.6355 - val_acc: 0.7902\n",
      "Epoch 82/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.8401e-04 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 0.7932\n",
      "Epoch 83/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6218 - val_acc: 0.7976\n",
      "Epoch 84/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6279 - val_acc: 0.8080\n",
      "Epoch 85/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6178 - val_acc: 0.8065\n",
      "Epoch 86/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.2188e-04 - acc: 1.0000 - val_loss: 0.5978 - val_acc: 0.8080\n",
      "Epoch 87/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.9663e-04 - acc: 1.0000 - val_loss: 0.5963 - val_acc: 0.8051\n",
      "Epoch 88/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 8.9483e-04 - acc: 1.0000 - val_loss: 0.6052 - val_acc: 0.8080\n",
      "Epoch 89/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.3598e-04 - acc: 1.0000 - val_loss: 0.6216 - val_acc: 0.8036\n",
      "Epoch 90/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.6832e-04 - acc: 1.0000 - val_loss: 0.6259 - val_acc: 0.8036\n",
      "Epoch 91/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.5210e-04 - acc: 1.0000 - val_loss: 0.6114 - val_acc: 0.8080\n",
      "Epoch 92/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.6933e-04 - acc: 1.0000 - val_loss: 0.6124 - val_acc: 0.8095\n",
      "Epoch 93/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.2471e-04 - acc: 1.0000 - val_loss: 0.6144 - val_acc: 0.8036\n",
      "Epoch 94/500\n",
      "384/384 [==============================] - 5s 12ms/step - loss: 6.1298e-04 - acc: 1.0000 - val_loss: 0.6172 - val_acc: 0.8021\n",
      "Epoch 95/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 5.8116e-04 - acc: 1.0000 - val_loss: 0.6122 - val_acc: 0.8006\n",
      "Epoch 96/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 5.4851e-04 - acc: 1.0000 - val_loss: 0.6163 - val_acc: 0.8036\n",
      "Epoch 97/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.4617e-04 - acc: 1.0000 - val_loss: 0.6219 - val_acc: 0.8051\n",
      "Epoch 98/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 5.1778e-04 - acc: 1.0000 - val_loss: 0.6305 - val_acc: 0.8021\n",
      "Epoch 99/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.6701e-04 - acc: 1.0000 - val_loss: 0.6302 - val_acc: 0.8021\n",
      "Epoch 100/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6174 - val_acc: 0.7991\n",
      "Epoch 101/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.9435 - val_acc: 0.7827\n",
      "Epoch 102/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0198 - acc: 0.9940 - val_loss: 0.7103 - val_acc: 0.8006\n",
      "Epoch 103/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.1913 - acc: 0.9315 - val_loss: 1.7298 - val_acc: 0.7574\n",
      "Epoch 104/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.3190 - acc: 0.8906 - val_loss: 2.8298 - val_acc: 0.7500\n",
      "Epoch 105/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.2472 - acc: 0.9048 - val_loss: 2.5686 - val_acc: 0.7530\n",
      "Epoch 106/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.1718 - acc: 0.9312 - val_loss: 2.0080 - val_acc: 0.7500\n",
      "Epoch 107/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0916 - acc: 0.9661 - val_loss: 1.2032 - val_acc: 0.7827\n",
      "Epoch 108/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0481 - acc: 0.9855 - val_loss: 1.2919 - val_acc: 0.7708\n",
      "Epoch 109/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0234 - acc: 0.9970 - val_loss: 1.0480 - val_acc: 0.7768\n",
      "Epoch 110/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0168 - acc: 0.9974 - val_loss: 0.8241 - val_acc: 0.7693\n",
      "Epoch 111/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.7872\n",
      "Epoch 112/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0085 - acc: 0.9996 - val_loss: 0.6726 - val_acc: 0.7917\n",
      "Epoch 113/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.6432 - val_acc: 0.7961\n",
      "Epoch 114/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0077 - acc: 0.9989 - val_loss: 0.6368 - val_acc: 0.7932\n",
      "Epoch 115/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.6245 - val_acc: 0.8051\n",
      "Epoch 116/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.6206 - val_acc: 0.8036\n",
      "Epoch 117/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.6066 - val_acc: 0.8051\n",
      "Epoch 118/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.6111 - val_acc: 0.8065\n",
      "Epoch 119/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.6147 - val_acc: 0.7946\n",
      "Epoch 120/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.6288 - val_acc: 0.7946\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 0.7976\n",
      "Epoch 122/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6291 - val_acc: 0.7961\n",
      "Epoch 123/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 0.7976\n",
      "Epoch 124/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 0.8036\n",
      "Epoch 125/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6245 - val_acc: 0.8021\n",
      "Epoch 126/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.8021\n",
      "Epoch 127/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 0.8065\n",
      "Epoch 128/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.8051\n",
      "Epoch 129/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 0.8065\n",
      "Epoch 130/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6474 - val_acc: 0.8065\n",
      "Epoch 131/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.6508 - val_acc: 0.8006\n",
      "Epoch 132/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.7917\n",
      "Epoch 133/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6553 - val_acc: 0.7902\n",
      "Epoch 134/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.6562 - val_acc: 0.7887\n",
      "Epoch 135/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 0.7917\n",
      "Epoch 136/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6537 - val_acc: 0.7946\n",
      "Epoch 137/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.8006\n",
      "Epoch 138/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6542 - val_acc: 0.7976\n",
      "Epoch 139/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6564 - val_acc: 0.7961\n",
      "Epoch 140/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6598 - val_acc: 0.7976\n",
      "Epoch 141/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.7991\n",
      "Epoch 142/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6625 - val_acc: 0.8021\n",
      "Epoch 143/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6723 - val_acc: 0.8036\n",
      "Epoch 144/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.5584e-04 - acc: 1.0000 - val_loss: 0.6747 - val_acc: 0.7991\n",
      "Epoch 145/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6740 - val_acc: 0.7991\n",
      "Epoch 146/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.0824e-04 - acc: 1.0000 - val_loss: 0.6710 - val_acc: 0.8036\n",
      "Epoch 147/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8021\n",
      "Epoch 148/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.7402e-04 - acc: 1.0000 - val_loss: 0.6611 - val_acc: 0.8051\n",
      "Epoch 149/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 0.8051\n",
      "Epoch 150/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.1918e-04 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 0.8021\n",
      "Epoch 151/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6607 - val_acc: 0.7946\n",
      "Epoch 152/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6611 - val_acc: 0.7961\n",
      "Epoch 153/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.7961\n",
      "Epoch 154/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6557 - val_acc: 0.7961\n",
      "Epoch 155/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6658 - val_acc: 0.7991\n",
      "Epoch 156/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.6222e-04 - acc: 1.0000 - val_loss: 0.6756 - val_acc: 0.8006\n",
      "Epoch 157/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.9302e-04 - acc: 1.0000 - val_loss: 0.6751 - val_acc: 0.7991\n",
      "Epoch 158/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.7454e-04 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 0.7961\n",
      "Epoch 159/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.7252e-04 - acc: 1.0000 - val_loss: 0.6765 - val_acc: 0.7991\n",
      "Epoch 160/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.6786 - val_acc: 0.7976\n",
      "Epoch 161/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.3991e-04 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.8006\n",
      "Epoch 162/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.7796e-04 - acc: 1.0000 - val_loss: 0.6849 - val_acc: 0.8006\n",
      "Epoch 163/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.7024e-04 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.7976\n",
      "Epoch 164/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6789 - val_acc: 0.7991\n",
      "Epoch 165/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.2213e-04 - acc: 1.0000 - val_loss: 0.6796 - val_acc: 0.7991\n",
      "Epoch 166/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.5303e-04 - acc: 1.0000 - val_loss: 0.6880 - val_acc: 0.7976\n",
      "Epoch 167/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.6040e-04 - acc: 1.0000 - val_loss: 0.6913 - val_acc: 0.8036\n",
      "Epoch 168/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.1636e-04 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 0.7976\n",
      "Epoch 169/500\n",
      "384/384 [==============================] - 5s 12ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6921 - val_acc: 0.7946\n",
      "Epoch 170/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 5.9917e-04 - acc: 1.0000 - val_loss: 0.6928 - val_acc: 0.7961\n",
      "Epoch 171/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.3635e-04 - acc: 1.0000 - val_loss: 0.6881 - val_acc: 0.7991\n",
      "Epoch 172/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.4101e-04 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 0.7976\n",
      "Epoch 173/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.0378e-04 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.8006\n",
      "Epoch 174/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.4691e-04 - acc: 1.0000 - val_loss: 0.6862 - val_acc: 0.7991\n",
      "Epoch 175/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.4237e-04 - acc: 1.0000 - val_loss: 0.6875 - val_acc: 0.8006\n",
      "Epoch 176/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2451e-04 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 0.7976\n",
      "Epoch 177/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.6580e-04 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 0.7976\n",
      "Epoch 178/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2431e-04 - acc: 1.0000 - val_loss: 0.6870 - val_acc: 0.7991\n",
      "Epoch 179/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.5232e-04 - acc: 1.0000 - val_loss: 0.6849 - val_acc: 0.7976\n",
      "Epoch 180/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 10ms/step - loss: 4.5838e-04 - acc: 1.0000 - val_loss: 0.6833 - val_acc: 0.7991\n",
      "Epoch 181/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.3771e-04 - acc: 1.0000 - val_loss: 0.6840 - val_acc: 0.8021\n",
      "Epoch 182/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.3262e-04 - acc: 1.0000 - val_loss: 0.6846 - val_acc: 0.8021\n",
      "Epoch 183/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.5527e-04 - acc: 1.0000 - val_loss: 0.6840 - val_acc: 0.8051\n",
      "Epoch 184/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2825e-04 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.8051\n",
      "Epoch 185/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.6185e-04 - acc: 1.0000 - val_loss: 0.6843 - val_acc: 0.8036\n",
      "Epoch 186/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.0951e-04 - acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.8036\n",
      "Epoch 187/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.4724e-04 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 0.8036\n",
      "Epoch 188/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.6628e-04 - acc: 1.0000 - val_loss: 0.6871 - val_acc: 0.8036\n",
      "Epoch 189/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.3808e-04 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 0.8021\n",
      "Epoch 190/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.2428e-04 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 0.8021\n",
      "Epoch 191/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.3634e-04 - acc: 1.0000 - val_loss: 0.6865 - val_acc: 0.8006\n",
      "Epoch 192/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.7747e-04 - acc: 1.0000 - val_loss: 0.6908 - val_acc: 0.8051\n",
      "Epoch 193/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.7567e-04 - acc: 1.0000 - val_loss: 0.6988 - val_acc: 0.8036\n",
      "Epoch 194/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.9133e-04 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.8006\n",
      "Epoch 195/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.6483e-04 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.8006\n",
      "Epoch 196/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.3492e-04 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.8006\n",
      "Epoch 197/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.7965e-04 - acc: 1.0000 - val_loss: 0.7118 - val_acc: 0.8021\n",
      "Epoch 198/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.6045e-04 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.7976\n",
      "Epoch 199/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.0542e-04 - acc: 1.0000 - val_loss: 0.7095 - val_acc: 0.8006\n",
      "Epoch 200/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.8109e-04 - acc: 1.0000 - val_loss: 0.7083 - val_acc: 0.7991\n",
      "Epoch 201/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.6480e-04 - acc: 1.0000 - val_loss: 0.7116 - val_acc: 0.7976\n",
      "Epoch 202/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.7730e-04 - acc: 1.0000 - val_loss: 0.7167 - val_acc: 0.8006\n",
      "Epoch 203/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.3127e-04 - acc: 1.0000 - val_loss: 0.7186 - val_acc: 0.8006\n",
      "Epoch 204/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.3470e-04 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.8006\n",
      "Epoch 205/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 2.8515e-04 - acc: 1.0000 - val_loss: 0.7140 - val_acc: 0.8006\n",
      "Epoch 206/500\n",
      "384/384 [==============================] - 4s 12ms/step - loss: 3.7997e-04 - acc: 1.0000 - val_loss: 0.7123 - val_acc: 0.8006\n",
      "Epoch 207/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.8565e-04 - acc: 1.0000 - val_loss: 0.7147 - val_acc: 0.7976\n",
      "Epoch 208/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.6879e-04 - acc: 1.0000 - val_loss: 0.7214 - val_acc: 0.8006\n",
      "Epoch 209/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.9660e-04 - acc: 1.0000 - val_loss: 0.7212 - val_acc: 0.8006\n",
      "Epoch 210/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 2.7724e-04 - acc: 1.0000 - val_loss: 0.7208 - val_acc: 0.8006\n",
      "Epoch 211/500\n",
      "384/384 [==============================] - 5s 13ms/step - loss: 4.0240e-04 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.8006\n",
      "Epoch 212/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.1830e-04 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.8006\n",
      "Epoch 213/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.2901e-04 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.8036\n",
      "Epoch 214/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.7178e-04 - acc: 1.0000 - val_loss: 0.7154 - val_acc: 0.7991\n",
      "Epoch 215/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.3408e-04 - acc: 1.0000 - val_loss: 0.7161 - val_acc: 0.7991\n",
      "Epoch 216/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.1718e-04 - acc: 1.0000 - val_loss: 0.7165 - val_acc: 0.8006\n",
      "Epoch 217/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.4932e-04 - acc: 1.0000 - val_loss: 0.7168 - val_acc: 0.7991\n",
      "Epoch 218/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.6954e-04 - acc: 1.0000 - val_loss: 0.7181 - val_acc: 0.7961\n",
      "Epoch 219/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.1924e-04 - acc: 1.0000 - val_loss: 0.7199 - val_acc: 0.7991\n",
      "Epoch 220/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.6830e-04 - acc: 1.0000 - val_loss: 0.7213 - val_acc: 0.8006\n",
      "Epoch 221/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.8302e-04 - acc: 1.0000 - val_loss: 0.7202 - val_acc: 0.7991\n",
      "Epoch 222/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8424e-04 - acc: 1.0000 - val_loss: 0.7208 - val_acc: 0.7991\n",
      "Epoch 223/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.3751e-04 - acc: 1.0000 - val_loss: 0.7224 - val_acc: 0.8006\n",
      "Epoch 224/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.4016e-04 - acc: 1.0000 - val_loss: 0.7241 - val_acc: 0.7991\n",
      "Epoch 225/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.1126e-04 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.7976\n",
      "Epoch 226/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.6229e-04 - acc: 1.0000 - val_loss: 0.7314 - val_acc: 0.8036\n",
      "Epoch 227/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.2347e-04 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.8021\n",
      "Epoch 228/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.0195e-04 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.8036\n",
      "Epoch 229/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.3102e-04 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.8036\n",
      "Epoch 230/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8368e-04 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.8036\n",
      "Epoch 231/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.0940e-04 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.8051\n",
      "Epoch 232/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.9655e-04 - acc: 1.0000 - val_loss: 0.7378 - val_acc: 0.8036\n",
      "Epoch 233/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.4421e-04 - acc: 1.0000 - val_loss: 0.7391 - val_acc: 0.8036\n",
      "Epoch 234/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.7839e-04 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.8021\n",
      "Epoch 235/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4335e-04 - acc: 1.0000 - val_loss: 0.7394 - val_acc: 0.8021\n",
      "Epoch 236/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8195e-04 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.8021\n",
      "Epoch 237/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8294e-04 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.7991\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5787e-04 - acc: 1.0000 - val_loss: 0.7380 - val_acc: 0.8021\n",
      "Epoch 239/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4225e-04 - acc: 1.0000 - val_loss: 0.7373 - val_acc: 0.8006\n",
      "Epoch 240/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6386e-04 - acc: 1.0000 - val_loss: 0.7370 - val_acc: 0.8006\n",
      "Epoch 241/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8731e-04 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.7991\n",
      "Epoch 242/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.9866e-04 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.7991\n",
      "Epoch 243/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6900e-04 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.8006\n",
      "Epoch 244/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6443e-04 - acc: 1.0000 - val_loss: 0.7348 - val_acc: 0.8006\n",
      "Epoch 245/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4652e-04 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.8006\n",
      "Epoch 246/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8647e-04 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.7991\n",
      "Epoch 247/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.0965e-04 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 0.8006\n",
      "Epoch 248/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.0733e-04 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.8006\n",
      "Epoch 249/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.0591e-04 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 0.8036\n",
      "Epoch 250/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.0914e-04 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 0.8006\n",
      "Epoch 251/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.0059e-04 - acc: 1.0000 - val_loss: 0.7238 - val_acc: 0.8036\n",
      "Epoch 252/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.0403e-04 - acc: 1.0000 - val_loss: 0.7228 - val_acc: 0.8021\n",
      "Epoch 253/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.4666e-04 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.8021\n",
      "Epoch 254/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.1333e-04 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.8021\n",
      "Epoch 255/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.7813e-05 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 0.8036\n",
      "Epoch 256/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.6851e-04 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 0.8036\n",
      "Epoch 257/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6133e-04 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 0.8036\n",
      "Epoch 258/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.9731e-04 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.8006\n",
      "Epoch 259/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.9522e-04 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.8006\n",
      "Epoch 260/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.0348e-04 - acc: 1.0000 - val_loss: 0.7409 - val_acc: 0.7976\n",
      "Epoch 261/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.1748e-04 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.8021\n",
      "Epoch 262/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1179e-04 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.8021\n",
      "Epoch 263/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3338e-04 - acc: 1.0000 - val_loss: 0.7477 - val_acc: 0.8051\n",
      "Epoch 264/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.7077e-04 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.8080\n",
      "Epoch 265/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4883e-04 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.8095\n",
      "Epoch 266/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.2223e-04 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.8051\n",
      "Epoch 267/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.4499e-04 - acc: 1.0000 - val_loss: 0.7447 - val_acc: 0.8065\n",
      "Epoch 268/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.7387e-04 - acc: 1.0000 - val_loss: 0.7441 - val_acc: 0.8065\n",
      "Epoch 269/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4763e-04 - acc: 1.0000 - val_loss: 0.7465 - val_acc: 0.8065\n",
      "Epoch 270/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.7835e-04 - acc: 1.0000 - val_loss: 0.7488 - val_acc: 0.8051\n",
      "Epoch 271/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6953e-04 - acc: 1.0000 - val_loss: 0.7497 - val_acc: 0.8021\n",
      "Epoch 272/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.5910e-04 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.8021\n",
      "Epoch 273/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.5336e-04 - acc: 1.0000 - val_loss: 0.7477 - val_acc: 0.7991\n",
      "Epoch 274/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6468e-04 - acc: 1.0000 - val_loss: 0.7452 - val_acc: 0.7991\n",
      "Epoch 275/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.2736e-04 - acc: 1.0000 - val_loss: 0.7405 - val_acc: 0.8036\n",
      "Epoch 276/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6514e-04 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 0.8021\n",
      "Epoch 277/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.0921e-04 - acc: 1.0000 - val_loss: 0.7423 - val_acc: 0.8036\n",
      "Epoch 278/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4050e-04 - acc: 1.0000 - val_loss: 0.7448 - val_acc: 0.8065\n",
      "Epoch 279/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8569e-04 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.8065\n",
      "Epoch 280/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.9161e-04 - acc: 1.0000 - val_loss: 0.7446 - val_acc: 0.7991\n",
      "Epoch 281/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8294e-04 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.8021\n",
      "Epoch 282/500\n",
      "384/384 [==============================] - 5s 12ms/step - loss: 1.6016e-04 - acc: 1.0000 - val_loss: 0.7472 - val_acc: 0.8021\n",
      "Epoch 283/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.6031e-04 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.7991\n",
      "Epoch 284/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.5952e-05 - acc: 1.0000 - val_loss: 0.7454 - val_acc: 0.8006\n",
      "Epoch 285/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.4755e-04 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.7946\n",
      "Epoch 286/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.3975e-04 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 0.7872\n",
      "Epoch 287/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.5864e-04 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 0.7887\n",
      "Epoch 288/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.2555e-04 - acc: 1.0000 - val_loss: 0.7385 - val_acc: 0.7902\n",
      "Epoch 289/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.7125e-04 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.7917\n",
      "Epoch 290/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.4920e-04 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 0.7917\n",
      "Epoch 291/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.3312e-04 - acc: 1.0000 - val_loss: 0.7351 - val_acc: 0.7932\n",
      "Epoch 292/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.0980e-04 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.7917\n",
      "Epoch 293/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.0419e-04 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.7932\n",
      "Epoch 294/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.1576e-04 - acc: 1.0000 - val_loss: 0.7355 - val_acc: 0.7946\n",
      "Epoch 295/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 8.7344e-05 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.7961\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 10ms/step - loss: 1.4653e-04 - acc: 1.0000 - val_loss: 0.7375 - val_acc: 0.7961\n",
      "Epoch 297/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0778e-04 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.7961\n",
      "Epoch 298/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5933e-04 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.7961\n",
      "Epoch 299/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.9889e-04 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.7946\n",
      "Epoch 300/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2721e-04 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.7991\n",
      "Epoch 301/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1686e-04 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.7976\n",
      "Epoch 302/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.7019e-04 - acc: 1.0000 - val_loss: 0.7587 - val_acc: 0.7991\n",
      "Epoch 303/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2827e-04 - acc: 1.0000 - val_loss: 0.7593 - val_acc: 0.7961\n",
      "Epoch 304/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.9513e-04 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 0.7946\n",
      "Epoch 305/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.6651e-05 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.8006\n",
      "Epoch 306/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5436e-04 - acc: 1.0000 - val_loss: 0.7603 - val_acc: 0.7961\n",
      "Epoch 307/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.7130e-04 - acc: 1.0000 - val_loss: 0.7681 - val_acc: 0.8006\n",
      "Epoch 308/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2788e-04 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.8006\n",
      "Epoch 309/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1580e-04 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 0.8006\n",
      "Epoch 310/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.0251e-04 - acc: 1.0000 - val_loss: 0.7703 - val_acc: 0.7976\n",
      "Epoch 311/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.6666e-05 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.7961\n",
      "Epoch 312/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6326e-04 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 0.7961\n",
      "Epoch 313/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1184e-04 - acc: 1.0000 - val_loss: 0.7677 - val_acc: 0.7946\n",
      "Epoch 314/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3551e-04 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.7976\n",
      "Epoch 315/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3415e-04 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.8006\n",
      "Epoch 316/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6135e-04 - acc: 1.0000 - val_loss: 0.7699 - val_acc: 0.8021\n",
      "Epoch 317/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0964e-04 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.8051\n",
      "Epoch 318/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0094e-04 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 0.8036\n",
      "Epoch 319/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.4901e-04 - acc: 1.0000 - val_loss: 0.7741 - val_acc: 0.7991\n",
      "Epoch 320/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2360e-04 - acc: 1.0000 - val_loss: 0.7762 - val_acc: 0.7991\n",
      "Epoch 321/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3724e-04 - acc: 1.0000 - val_loss: 0.7752 - val_acc: 0.7991\n",
      "Epoch 322/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6261e-04 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.7991\n",
      "Epoch 323/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.3424e-05 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.7976\n",
      "Epoch 324/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.4546e-05 - acc: 1.0000 - val_loss: 0.7749 - val_acc: 0.7991\n",
      "Epoch 325/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.1145e-05 - acc: 1.0000 - val_loss: 0.7747 - val_acc: 0.8006\n",
      "Epoch 326/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.8616e-05 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.7991\n",
      "Epoch 327/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.1540e-04 - acc: 1.0000 - val_loss: 0.7709 - val_acc: 0.7976\n",
      "Epoch 328/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3056e-04 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7961\n",
      "Epoch 329/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.8192e-05 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.7961\n",
      "Epoch 330/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2438e-04 - acc: 1.0000 - val_loss: 0.7730 - val_acc: 0.7991\n",
      "Epoch 331/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.0703e-05 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.7976\n",
      "Epoch 332/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.5408e-05 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.7961\n",
      "Epoch 333/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.4374e-04 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.7976\n",
      "Epoch 334/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.2137e-04 - acc: 1.0000 - val_loss: 0.7729 - val_acc: 0.8006\n",
      "Epoch 335/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.8000e-05 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.7976\n",
      "Epoch 336/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3964e-04 - acc: 1.0000 - val_loss: 0.7766 - val_acc: 0.7976\n",
      "Epoch 337/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2121e-04 - acc: 1.0000 - val_loss: 0.7833 - val_acc: 0.8036\n",
      "Epoch 338/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.0437e-04 - acc: 1.0000 - val_loss: 0.7847 - val_acc: 0.8021\n",
      "Epoch 339/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.8298e-05 - acc: 1.0000 - val_loss: 0.7821 - val_acc: 0.8021\n",
      "Epoch 340/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0031e-04 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 0.8006\n",
      "Epoch 341/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5946e-04 - acc: 1.0000 - val_loss: 0.7781 - val_acc: 0.8006\n",
      "Epoch 342/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.3045e-04 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 0.8021\n",
      "Epoch 343/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.9472e-05 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 0.8006\n",
      "Epoch 344/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.7027e-05 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.8006\n",
      "Epoch 345/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.6136e-04 - acc: 1.0000 - val_loss: 0.7770 - val_acc: 0.7976\n",
      "Epoch 346/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5933e-04 - acc: 1.0000 - val_loss: 0.7761 - val_acc: 0.7961\n",
      "Epoch 347/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.4455e-04 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 0.7932\n",
      "Epoch 348/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.3428e-05 - acc: 1.0000 - val_loss: 0.7797 - val_acc: 0.7902\n",
      "Epoch 349/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.5453e-05 - acc: 1.0000 - val_loss: 0.7765 - val_acc: 0.7902\n",
      "Epoch 350/500\n",
      "384/384 [==============================] - 4s 12ms/step - loss: 1.1599e-04 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.7917\n",
      "Epoch 351/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.2497e-04 - acc: 1.0000 - val_loss: 0.7709 - val_acc: 0.7961\n",
      "Epoch 352/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.3272e-05 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.7991\n",
      "Epoch 353/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.6125e-05 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.7976\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2392e-04 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7991\n",
      "Epoch 355/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1025e-04 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.7976\n",
      "Epoch 356/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.4427e-05 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.7961\n",
      "Epoch 357/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.5475e-05 - acc: 1.0000 - val_loss: 0.7734 - val_acc: 0.7961\n",
      "Epoch 358/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.2690e-04 - acc: 1.0000 - val_loss: 0.7719 - val_acc: 0.8021\n",
      "Epoch 359/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.9454e-04 - acc: 1.0000 - val_loss: 0.7761 - val_acc: 0.7961\n",
      "Epoch 360/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.5879e-05 - acc: 1.0000 - val_loss: 0.7799 - val_acc: 0.7976\n",
      "Epoch 361/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.3385e-05 - acc: 1.0000 - val_loss: 0.7819 - val_acc: 0.7961\n",
      "Epoch 362/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.5742e-05 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.7946\n",
      "Epoch 363/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.6988e-05 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.7946\n",
      "Epoch 364/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.7602e-05 - acc: 1.0000 - val_loss: 0.7773 - val_acc: 0.7946\n",
      "Epoch 365/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1443e-04 - acc: 1.0000 - val_loss: 0.7796 - val_acc: 0.7946\n",
      "Epoch 366/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.2769e-05 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 0.7961\n",
      "Epoch 367/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.2779e-05 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.7946\n",
      "Epoch 368/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2396e-04 - acc: 1.0000 - val_loss: 0.7861 - val_acc: 0.7946\n",
      "Epoch 369/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.5469e-05 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.7932\n",
      "Epoch 370/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.4628e-05 - acc: 1.0000 - val_loss: 0.7900 - val_acc: 0.7946\n",
      "Epoch 371/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.7830e-05 - acc: 1.0000 - val_loss: 0.7923 - val_acc: 0.7961\n",
      "Epoch 372/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.5095e-05 - acc: 1.0000 - val_loss: 0.7907 - val_acc: 0.7976\n",
      "Epoch 373/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.7224e-05 - acc: 1.0000 - val_loss: 0.7892 - val_acc: 0.7946\n",
      "Epoch 374/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.7021e-05 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.7932\n",
      "Epoch 375/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.5035e-05 - acc: 1.0000 - val_loss: 0.7913 - val_acc: 0.7932\n",
      "Epoch 376/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.5450e-05 - acc: 1.0000 - val_loss: 0.7935 - val_acc: 0.7917\n",
      "Epoch 377/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.5718e-05 - acc: 1.0000 - val_loss: 0.7940 - val_acc: 0.7917\n",
      "Epoch 378/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.1895e-05 - acc: 1.0000 - val_loss: 0.7946 - val_acc: 0.7961\n",
      "Epoch 379/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.4366e-05 - acc: 1.0000 - val_loss: 0.7960 - val_acc: 0.7976\n",
      "Epoch 380/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.8423e-05 - acc: 1.0000 - val_loss: 0.7965 - val_acc: 0.7991\n",
      "Epoch 381/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.6689e-05 - acc: 1.0000 - val_loss: 0.7957 - val_acc: 0.7946\n",
      "Epoch 382/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.2838e-04 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.7932\n",
      "Epoch 383/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.4008e-05 - acc: 1.0000 - val_loss: 0.7938 - val_acc: 0.7976\n",
      "Epoch 384/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.9159e-05 - acc: 1.0000 - val_loss: 0.7940 - val_acc: 0.7976\n",
      "Epoch 385/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.1808e-05 - acc: 1.0000 - val_loss: 0.7971 - val_acc: 0.7917\n",
      "Epoch 386/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.9692e-05 - acc: 1.0000 - val_loss: 0.8028 - val_acc: 0.7917\n",
      "Epoch 387/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.5946e-05 - acc: 1.0000 - val_loss: 0.8096 - val_acc: 0.7946\n",
      "Epoch 388/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.6175e-05 - acc: 1.0000 - val_loss: 0.8146 - val_acc: 0.7946\n",
      "Epoch 389/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0860e-04 - acc: 1.0000 - val_loss: 0.8093 - val_acc: 0.7946\n",
      "Epoch 390/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 7.6004e-05 - acc: 1.0000 - val_loss: 0.8067 - val_acc: 0.7991\n",
      "Epoch 391/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.3228e-05 - acc: 1.0000 - val_loss: 0.8065 - val_acc: 0.7976\n",
      "Epoch 392/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.2014e-05 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.7946\n",
      "Epoch 393/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.1666e-05 - acc: 1.0000 - val_loss: 0.8061 - val_acc: 0.7946\n",
      "Epoch 394/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.4521e-05 - acc: 1.0000 - val_loss: 0.8089 - val_acc: 0.7946\n",
      "Epoch 395/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.5154e-05 - acc: 1.0000 - val_loss: 0.8115 - val_acc: 0.7961\n",
      "Epoch 396/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.6967e-05 - acc: 1.0000 - val_loss: 0.8127 - val_acc: 0.7946\n",
      "Epoch 397/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.0528e-05 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.7961\n",
      "Epoch 398/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 9.4049e-05 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 0.7961\n",
      "Epoch 399/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.6764e-04 - acc: 1.0000 - val_loss: 0.8150 - val_acc: 0.7991\n",
      "Epoch 400/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.8138e-05 - acc: 1.0000 - val_loss: 0.8154 - val_acc: 0.7976\n",
      "Epoch 401/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.7091e-05 - acc: 1.0000 - val_loss: 0.8093 - val_acc: 0.7976\n",
      "Epoch 402/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.8618e-05 - acc: 1.0000 - val_loss: 0.8075 - val_acc: 0.7961\n",
      "Epoch 403/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.1979e-05 - acc: 1.0000 - val_loss: 0.8074 - val_acc: 0.7932\n",
      "Epoch 404/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.8789e-05 - acc: 1.0000 - val_loss: 0.8046 - val_acc: 0.7917\n",
      "Epoch 405/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.3004e-05 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.7887\n",
      "Epoch 406/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 9.2095e-05 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.7887\n",
      "Epoch 407/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 5.3409e-05 - acc: 1.0000 - val_loss: 0.8137 - val_acc: 0.7946\n",
      "Epoch 408/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.5045e-04 - acc: 1.0000 - val_loss: 0.8142 - val_acc: 0.7932\n",
      "Epoch 409/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1645e-04 - acc: 1.0000 - val_loss: 0.8154 - val_acc: 0.7917\n",
      "Epoch 410/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.3703e-05 - acc: 1.0000 - val_loss: 0.8164 - val_acc: 0.7902\n",
      "Epoch 411/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.5359e-05 - acc: 1.0000 - val_loss: 0.8165 - val_acc: 0.7902\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 4s 10ms/step - loss: 4.6947e-05 - acc: 1.0000 - val_loss: 0.8174 - val_acc: 0.7932\n",
      "Epoch 413/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.4283e-05 - acc: 1.0000 - val_loss: 0.8170 - val_acc: 0.7946\n",
      "Epoch 414/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2484e-05 - acc: 1.0000 - val_loss: 0.8183 - val_acc: 0.7961\n",
      "Epoch 415/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.5516e-05 - acc: 1.0000 - val_loss: 0.8190 - val_acc: 0.7961\n",
      "Epoch 416/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.6610e-05 - acc: 1.0000 - val_loss: 0.8199 - val_acc: 0.7932\n",
      "Epoch 417/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.1985e-05 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.7932\n",
      "Epoch 418/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.0538e-05 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.7917\n",
      "Epoch 419/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.7960e-05 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.7946\n",
      "Epoch 420/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.9657e-05 - acc: 1.0000 - val_loss: 0.8253 - val_acc: 0.7946\n",
      "Epoch 421/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.8707e-05 - acc: 1.0000 - val_loss: 0.8212 - val_acc: 0.7917\n",
      "Epoch 422/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.8131e-05 - acc: 1.0000 - val_loss: 0.8180 - val_acc: 0.7902\n",
      "Epoch 423/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.6587e-05 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 0.7902\n",
      "Epoch 424/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.7295e-04 - acc: 1.0000 - val_loss: 0.8319 - val_acc: 0.7902\n",
      "Epoch 425/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.5169e-05 - acc: 1.0000 - val_loss: 0.8357 - val_acc: 0.7932\n",
      "Epoch 426/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.2592e-05 - acc: 1.0000 - val_loss: 0.8412 - val_acc: 0.7946\n",
      "Epoch 427/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.9875e-05 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.7961\n",
      "Epoch 428/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.7269e-04 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.7917\n",
      "Epoch 429/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.1758e-04 - acc: 1.0000 - val_loss: 0.8444 - val_acc: 0.7887\n",
      "Epoch 430/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.9170e-05 - acc: 1.0000 - val_loss: 0.8410 - val_acc: 0.7902\n",
      "Epoch 431/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.3503e-05 - acc: 1.0000 - val_loss: 0.8361 - val_acc: 0.7902\n",
      "Epoch 432/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.3513e-05 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.7932\n",
      "Epoch 433/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 7.2049e-05 - acc: 1.0000 - val_loss: 0.8310 - val_acc: 0.7961\n",
      "Epoch 434/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.3814e-05 - acc: 1.0000 - val_loss: 0.8283 - val_acc: 0.7932\n",
      "Epoch 435/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.4017e-05 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.7946\n",
      "Epoch 436/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.2169e-05 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 0.7991\n",
      "Epoch 437/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.1629e-05 - acc: 1.0000 - val_loss: 0.8217 - val_acc: 0.8036\n",
      "Epoch 438/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.2435e-05 - acc: 1.0000 - val_loss: 0.8200 - val_acc: 0.8006\n",
      "Epoch 439/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.3513e-05 - acc: 1.0000 - val_loss: 0.8253 - val_acc: 0.7991\n",
      "Epoch 440/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.4839e-05 - acc: 1.0000 - val_loss: 0.8351 - val_acc: 0.8006\n",
      "Epoch 441/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 8.7319e-05 - acc: 1.0000 - val_loss: 0.8371 - val_acc: 0.8036\n",
      "Epoch 442/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.0584e-05 - acc: 1.0000 - val_loss: 0.8434 - val_acc: 0.8021\n",
      "Epoch 443/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.2677e-05 - acc: 1.0000 - val_loss: 0.8456 - val_acc: 0.8036\n",
      "Epoch 444/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.9777e-05 - acc: 1.0000 - val_loss: 0.8460 - val_acc: 0.8065\n",
      "Epoch 445/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.0394e-05 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.8051\n",
      "Epoch 446/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.2228e-05 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.8021\n",
      "Epoch 447/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2189e-05 - acc: 1.0000 - val_loss: 0.8441 - val_acc: 0.8051\n",
      "Epoch 448/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0331e-04 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.7991\n",
      "Epoch 449/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.9710e-05 - acc: 1.0000 - val_loss: 0.8295 - val_acc: 0.8006\n",
      "Epoch 450/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.4886e-05 - acc: 1.0000 - val_loss: 0.8304 - val_acc: 0.8006\n",
      "Epoch 451/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.0123e-04 - acc: 1.0000 - val_loss: 0.8332 - val_acc: 0.8006\n",
      "Epoch 452/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.8220e-05 - acc: 1.0000 - val_loss: 0.8517 - val_acc: 0.7991\n",
      "Epoch 453/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.4352e-05 - acc: 1.0000 - val_loss: 0.8391 - val_acc: 0.8036\n",
      "Epoch 454/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.2421e-05 - acc: 1.0000 - val_loss: 0.8347 - val_acc: 0.8006\n",
      "Epoch 455/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.1695e-05 - acc: 1.0000 - val_loss: 0.8334 - val_acc: 0.8006\n",
      "Epoch 456/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 6.1911e-05 - acc: 1.0000 - val_loss: 0.8335 - val_acc: 0.8006\n",
      "Epoch 457/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.9369e-05 - acc: 1.0000 - val_loss: 0.8321 - val_acc: 0.8021\n",
      "Epoch 458/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.7311e-05 - acc: 1.0000 - val_loss: 0.8342 - val_acc: 0.8006\n",
      "Epoch 459/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.4083e-05 - acc: 1.0000 - val_loss: 0.8363 - val_acc: 0.8036\n",
      "Epoch 460/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.6870e-05 - acc: 1.0000 - val_loss: 0.8376 - val_acc: 0.8036\n",
      "Epoch 461/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.5448e-05 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.8006\n",
      "Epoch 462/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 5.9462e-05 - acc: 1.0000 - val_loss: 0.8443 - val_acc: 0.8006\n",
      "Epoch 463/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.1251e-05 - acc: 1.0000 - val_loss: 0.8449 - val_acc: 0.8036\n",
      "Epoch 464/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.2495e-05 - acc: 1.0000 - val_loss: 0.8452 - val_acc: 0.8006\n",
      "Epoch 465/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.1346e-05 - acc: 1.0000 - val_loss: 0.8468 - val_acc: 0.7976\n",
      "Epoch 466/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.5189e-05 - acc: 1.0000 - val_loss: 0.8534 - val_acc: 0.7946\n",
      "Epoch 467/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.9869e-05 - acc: 1.0000 - val_loss: 0.8561 - val_acc: 0.7961\n",
      "Epoch 468/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.1035e-05 - acc: 1.0000 - val_loss: 0.8571 - val_acc: 0.7961\n",
      "Epoch 469/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.0921e-05 - acc: 1.0000 - val_loss: 0.8583 - val_acc: 0.7946\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 5s 14ms/step - loss: 5.1490e-05 - acc: 1.0000 - val_loss: 0.8577 - val_acc: 0.7961\n",
      "Epoch 471/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.9520e-05 - acc: 1.0000 - val_loss: 0.8626 - val_acc: 0.7946\n",
      "Epoch 472/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.6768e-05 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.7961\n",
      "Epoch 473/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.3473e-05 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.7961\n",
      "Epoch 474/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.2100e-05 - acc: 1.0000 - val_loss: 0.8578 - val_acc: 0.7976\n",
      "Epoch 475/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 6.4634e-05 - acc: 1.0000 - val_loss: 0.8574 - val_acc: 0.7976\n",
      "Epoch 476/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.5123e-05 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.7946\n",
      "Epoch 477/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.6024e-05 - acc: 1.0000 - val_loss: 0.8560 - val_acc: 0.7991\n",
      "Epoch 478/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.8873e-05 - acc: 1.0000 - val_loss: 0.8548 - val_acc: 0.8036\n",
      "Epoch 479/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.8938e-05 - acc: 1.0000 - val_loss: 0.8550 - val_acc: 0.8095\n",
      "Epoch 480/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 3.4522e-05 - acc: 1.0000 - val_loss: 0.8566 - val_acc: 0.8051\n",
      "Epoch 481/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.5023e-05 - acc: 1.0000 - val_loss: 0.8559 - val_acc: 0.8036\n",
      "Epoch 482/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1317e-05 - acc: 1.0000 - val_loss: 0.8568 - val_acc: 0.8065\n",
      "Epoch 483/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.5856e-05 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.8065\n",
      "Epoch 484/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.0099e-05 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.8095\n",
      "Epoch 485/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1177e-05 - acc: 1.0000 - val_loss: 0.8478 - val_acc: 0.8095\n",
      "Epoch 486/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.7995e-05 - acc: 1.0000 - val_loss: 0.8452 - val_acc: 0.8080\n",
      "Epoch 487/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 4.0341e-05 - acc: 1.0000 - val_loss: 0.8475 - val_acc: 0.8051\n",
      "Epoch 488/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3424e-05 - acc: 1.0000 - val_loss: 0.8498 - val_acc: 0.8051\n",
      "Epoch 489/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.3157e-05 - acc: 1.0000 - val_loss: 0.8494 - val_acc: 0.8051\n",
      "Epoch 490/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 3.7287e-05 - acc: 1.0000 - val_loss: 0.8493 - val_acc: 0.8036\n",
      "Epoch 491/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.5953e-05 - acc: 1.0000 - val_loss: 0.8494 - val_acc: 0.8036\n",
      "Epoch 492/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1062e-05 - acc: 1.0000 - val_loss: 0.8502 - val_acc: 0.8036\n",
      "Epoch 493/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.8040e-05 - acc: 1.0000 - val_loss: 0.8505 - val_acc: 0.8080\n",
      "Epoch 494/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1442e-05 - acc: 1.0000 - val_loss: 0.8542 - val_acc: 0.8021\n",
      "Epoch 495/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 4.5819e-05 - acc: 1.0000 - val_loss: 0.8584 - val_acc: 0.8021\n",
      "Epoch 496/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 1.9455e-05 - acc: 1.0000 - val_loss: 0.8638 - val_acc: 0.8036\n",
      "Epoch 497/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.8044e-05 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.8036\n",
      "Epoch 498/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.3889e-05 - acc: 1.0000 - val_loss: 0.8613 - val_acc: 0.8021\n",
      "Epoch 499/500\n",
      "384/384 [==============================] - 4s 11ms/step - loss: 2.1899e-05 - acc: 1.0000 - val_loss: 0.8603 - val_acc: 0.8021\n",
      "Epoch 500/500\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.3750e-05 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 0.8021\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_train, y_train, batch_size=32, epochs=500, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XeYVNX5wPHvu7MVWOpioYNiwQaKqLGiUbHX2GKiRkOKGlM0UWPUmKJpxp8lKibYeycGRVQwRlFERAWlC7KAdJaybcr5/fHey9ydnd2ZLbO7zLyf59lnZm6ZOXd39r73vOfcc8Q5hzHGGNOYvPYugDHGmI7PgoUxxpiULFgYY4xJyYKFMcaYlCxYGGOMScmChTHGmJQsWBgDiMhDIvL7NLddIiLfzHSZjOlILFgYY4xJyYKFMVlERPLbuwwmO1mwMNsNL/1zjYh8KiJbReRfIrKjiLwqIptF5A0R6RHY/lQRmSMiG0VkqojsGVg3QkRmevs9DRQnfNbJIjLL2/c9Edk3zTKeJCIfi8gmEVkmIjcnrD/Me7+N3vqLveUlIvI3EVkqIhUi8j9v2VEiUp7k9/BN7/nNIvKciDwmIpuAi0VklIhM8z5jpYjcLSKFgf33EpHJIrJeRFaJyPUispOIVIpIr8B2+4vIGhEpSOfYTXazYGG2N2cBxwK7AacArwLXA73R7/NPAERkN+BJ4KfeuonAv0Wk0DtxvgQ8CvQEnvXeF2/fEcB44AdAL+B+YIKIFKVRvq3Ad4HuwEnAj0TkdO99B3rlvcsr03BglrffX4EDgG94ZfolEEvzd3Ia8Jz3mY8DUeBnQBlwCHAM8GOvDKXAG8BrQB9gV+BN59zXwFTgnMD7fgd4yjkXTrMcJotZsDDbm7ucc6ucc8uBd4APnHMfO+eqgReBEd525wL/cc5N9k52fwVK0JPxwUABcIdzLuycew74MPAZY4H7nXMfOOeizrmHgRpvv0Y556Y65z5zzsWcc5+iAetIb/UFwBvOuSe9z13nnJslInnA94CrnHPLvc98zzlXk+bvZJpz7iXvM6uccx855953zkWcc0vQYOeX4WTga+fc35xz1c65zc65D7x1DwMXAohICDgfDajGWLAw251VgedVSV538Z73AZb6K5xzMWAZ0Ndbt9zVHUVzaeD5QOAXXhpno4hsBPp7+zVKRA4SkSle+qYC+CF6hY/3HouS7FaGpsGSrUvHsoQy7CYir4jI115q6o9plAHgZWCYiAxGa28VzrnpzSyTyTIWLEy2WoGe9AEQEUFPlMuBlUBfb5lvQOD5MuAPzrnugZ9Ozrkn0/jcJ4AJQH/nXDfgPsD/nGXALkn2WQtUN7BuK9ApcBwhNIUVlDh09L3AXGCoc64rmqYLlmFIsoJ7tbNn0NrFd7BahQmwYGGy1TPASSJyjNdA+ws0lfQeMA2IAD8RkQIRORMYFdj3AeCHXi1BRKSz13BdmsbnlgLrnXPVIjIKTT35Hge+KSLniEi+iPQSkeFerWc8cLuI9BGRkIgc4rWRzAeKvc8vAG4AUrWdlAKbgC0isgfwo8C6V4CdReSnIlIkIqUiclBg/SPAxcCpWLAwARYsTFZyzs1Dr5DvQq/cTwFOcc7VOudqgTPRk+J6tH3jhcC+M4DvA3cDG4CF3rbp+DFwi4hsBm5Eg5b/vl8BJ6KBaz3auL2ft/pq4DO07WQ98CcgzzlX4b3nP9Fa0VagTu+oJK5Gg9RmNPA9HSjDZjTFdArwNbAAGB1Y/y7asD7TORdMzZkcJzb5kTEmSETeAp5wzv2zvctiOg4LFsaYbUTkQGAy2uayub3LYzoOS0MZYwAQkYfRezB+aoHCJLKahTHGmJSsZmGMMSalrBl0rKyszA0aNKi9i2GMMduVjz76aK1zLvHenXqyJlgMGjSIGTNmtHcxjDFmuyIiaXWRtjSUMcaYlCxYGGOMScmChTHGmJSyps0imXA4THl5OdXV1e1dlIwrLi6mX79+FBTYPDXGmNaX1cGivLyc0tJSBg0aRN0BRrOLc45169ZRXl7O4MGD27s4xpgslLE0lIiMF5HVIjK7gfUiIneKyELRaTL3D6y7SEQWeD8XNbcM1dXV9OrVK6sDBYCI0KtXr5yoQRlj2kcm2yweAsY0sv4EYKj3MxYdgx8R6QncBByEDht9kwTmVW6qbA8Uvlw5TmNM+8hYGso5918RGdTIJqcBj3izlb0vIt1FZGfgKGCyc249gIhMRoNOOhPPZIxzjk3VEUQgEo0RjjoEiKUxWooIGdk20aaqMLe/Pi+tbUcM7MHo3Xeot/zVz1aybEMlPTsXUb6hkuKCENXhKAWhPGrC0XrbF+bn4RyEo+lOF51cSWE+VeEo2PAzxjTZTt1KuOCgAak3bIH2bLPoS93pIMu9ZQ0tr0dExqK1EgYMyMwvKhKN8eXarYTyhC01kSbvv6migldfepZzL7qsSftd/t1vcetd/6Rrt25p77O5OsJdU5al3M4/Hz9+2UEcumvZtuVfV1Tzo8dnNrpvYgXGf6+WVGyC8cEqSMY03fD+3bM6WLSYc24cMA5g5MiRGbkk3VIT0SteoHNhPgj07FRIl+J8Ys5RlB9qdP8lkY289ORD3Pirn9XZNhKJkJ9f/9dfG4kBjnfemtzksn6xuYQvbz0p5XbV4Sh73TSJ9xatrRMsnp+pc+pcfdxu/G/hWq48eihdiwvo16OE1Ztr2G3HLvXSXcvWV5IfEnbuVtLk8vqcc8xZsYkhvTvTqXC7/koak7Xa8z9zOTonsq+ft2w5mooKLp/aZqVKsLk6QihP2H3HUvLyhLwmXvpee+21LF60iINGHkBBQQHFxcX06NGDuXPnMn/+fE4//XSWLVtGdXU1V111FWPHjgXiw5ds2bKFE044gcMOO4z33nuPvn378vLLL1NS0vyTc3FBiAE9O/Hl2q3bli1dt5XbJ89nSFlnLh+9K1ccPbTOPj06FyZ9r/49OyVd3hQiwt59069BGWPaXnsGiwnAFSLyFNqYXeGcWykik4A/Bhq1jwOua+mH/fbfc/h8xaYm7RONOarDUfJDeRTl1+8LMKxPV246Za9G3+O2225j9uzZzJo1i6lTp3LSSScxe/bsbV1cx48fT8+ePamqquLAAw/krLPOolevXnXeY8GCBTz55JM88MADnHPOOTz//PNceOGFTTqWRIPLOrN4TTBYVBKNOW4+dS9rLDfG1JOxYCEiT6I1hDIRKUd7OBUAOOfuAyai8xEvBCqBS7x160Xkd+hcxAC3+I3dbS3mJdOTBYrmGjVqVJ17Ie68805efPFFAJYtW8aCBQvqBYvBgwczfPhwAA444ACWLFnS4nIMLuvMe4vWEos58vKEiqowADt3K27xextjsk8me0Odn2K9Ay5vYN14YHxrlidVDSCZ5Rur2FhZy159Wi9F0rlz523Pp06dyhtvvMG0adPo1KkTRx11VNJ7JYqKirY9D4VCVFVVtbgcPTsXUh2OURuNUZwX2hYsupXYHeDGmPpsbKhGhCMxCkIt+xWVlpayeXPyGSorKiro0aMHnTp1Yu7cubz//vst+qymCOVpqsmvPfnBoqsFC2NMEtb1pBHhaIzCFgaLXr16ceihh7L33ntTUlLCjjvuuG3dmDFjuO+++9hzzz3ZfffdOfjgg1ta5LSFvHaJaCweLIry8yguaLx3lzEmN1mwaEAs5qiNxuhU2PKT5xNPPJF0eVFREa+++mrSdX67RFlZGbNnx0dMufrqq1tcHoA8v2bh3UtXURm2FJQxpkGWhmrA6s01RGOO0uLsPIGGvA5P0UAayoKFMaYhFiwaUBOJUpwfytocvt9mEUxDde+UncdqjGk5CxYNCEcd+aHsvd8glKd/ej9YbKoO0zVLa1HGmJazYNGASCxGfgsbtzsy/9D8NFRlbZTORdaEZYxJLnvPhi3gnCMSdRTkZW/Nwh+2JObVLKpqo5RYTyhjTAMsWCQRc46Yy/Y0VN02i6pwlJJW6PlljMlOFiySiET1BNoaaaiNGzfyj3/8o1n73nHHHVRWVra4DMlsCxYuULOwYGGMaYAFiyQi3tV2fiukoTpqsAimoSJRHfbD0lDGmIZYi2YS/tV2U4cjT+baa69l0aJFDB8+nGOPPZYddtiBZ555hpqaGs444wx++9vfsnXrVs455xzKy8uJRqP85je/YdWqVaxYsYLRo0dTVlbGlClTWlyWID8QRmKO6ojemWfBwhjTkNwJFq9eC19/ltamnWIxhoRjmpZpLGDstA+ccFuj7xUcovz111/nueeeY/r06TjnOPXUU/nvf//LmjVr6NOnD//5z38AHTOqW7du3H777UyZMoWysrJGP6M58gJtFlW1OrlTsaWhjDENsDRUEpmaBvr111/n9ddfZ8SIEey///7MnTuXBQsWsM8++zB58mR+9atf8c4779CtCVOpNpc/NlTM6ZwdYDULY0zDcqdmkaIGELRxczUrK6p1aPJW7D7rnOO6667jBz/4Qb11M2fOZOLEidxwww0cc8wx3Hjjja32uckEe0P508a2xjhYxpjsZDWLJKIxEFonTgSHKD/++OMZP348W7ZsAWD58uWsXr2aFStW0KlTJy688EKuueYaZs6cWW/f1pYXGKK8stZqFsaYxuVOzaIJok5nj2uN6UWDQ5SfcMIJXHDBBRxyyCEAdOnShccee4yFCxdyzTXXkJeXR0FBAffeey8AY8eOZcyYMfTp06fVG7jjQ5RDbcRrs7BgYYxpgAWLJGIxt+1k2hoShyi/6qqr6rzeZZddOP744+vtd+WVV3LllVe2WjmCQtt6Q8WoCXu9oSwNZYxpgKWhkoh681Jns1BgPgtrszDGpGLBIomoa92aRUcUHEiwytosjDEpZH2wcM3oBxuLuW1X3tuLph5n8A7uyrC1WRhjGpfVwaK4uJh169Y1+UQac63aYzbjnHOsW7eO4uLitPcJdp2t8YJFYX5Wfx2MMS2Q1Q3c/fr1o7y8nDVr1jRpv5UV1RQX5LF1dWGGStb6iouL6devX9rb+zWLqHPbxsIqsmBhjGlAVgeLgoICBg8e3OT9zr15Emfu34+bT90zA6XqGOIN3I6wNzZUawycaIzJTnYpmURVOJr1+fvgQILhaAwRtrt2GmNM27FgkSAcjRGOuqzvRhq8gzsccxSE8lrlJkRjTHayYJEgV+45iN/BrWmobJ5C1hjTchYsEmwbrjvL01DB3lDhaIwCa9w2xjTCzhAJ/EH1sr1mkZiGys+zr4IxpmF2hkhQlSPBIjiQYDgSozBkaShjTMMsWCSoCkcAKCnM6l7FgTRUzNJQxpiUMnqGEJExIjJPRBaKyLVJ1g8UkTdF5FMRmSoi/QLroiIyy/uZkMlyBuXK3A512ixizu6xMMY0KmOXzyISAu4BjgXKgQ9FZIJz7vPAZn8FHnHOPSwiRwO3At/x1lU554ZnqnwNybk0lNM0VEHIahbGmIZl8gwxCljonFvsnKsFngJOS9hmGPCW93xKkvVtzu86m+1zO/jt2TGvN5SNC2WMaUwmzxB9gWWB1+XesqBPgDO952cApSLSy3tdLCIzROR9ETk92QeIyFhvmxlNHf+pITmXhvLGhrI0lDGmMe19OXk1cKSIfAwcCSwHot66gc65kcAFwB0iskvizs65cc65kc65kb17926VAuVM19nATXm1loYyxqSQyS4/y4H+gdf9vGXbOOdW4NUsRKQLcJZzbqO3brn3uFhEpgIjgEUZLC8A1TmShsoPDiQYjdG5KLt7fxljWiaTl5MfAkNFZLCIFALnAXV6NYlImYj4ZbgOGO8t7yEiRf42wKFAsGE8YyprI4TyhMIsv9IOBQYStDSUMSaVjJ0RnXMR4ApgEvAF8Ixzbo6I3CIip3qbHQXME5H5wI7AH7zlewIzROQTtOH7toReVBlTWRulpCCU9YPqiQgiege3paGMMalkNPfgnJsITExYdmPg+XPAc0n2ew/YJ5Nla0h1OJr1KShfSMTGhjLGpMXOEAkqa6NZ37jty8uTbb2hbNRZY0xjLFgk8NNQuSAksm2mPEtDGWMaY2eIBFW1uZOGys8TojGojTryLVgYYxphZ4gEVeEcS0PFYkRiNuqsMaZxFiwSaBoqN+45CHltFpaGMsakYmeIBFW1kZxJQ+WJpqHCloYyxqRgZ4gEVeEonXKlgTvPu4Pb0lDGmBQsWCSozKEG7pAItdEYzmFpKGNMo+wMkSCXekOFQrJt/g5LQxljGmNniIDaSIxIzOVMGio/L49Kb+BEm8/CGNMYO0MEbKnR+be7FOdGb6j8PKHSO+YiCxbGmEbYGSJgU1UYgG4lBe1ckraRH8rbFiCtZmGMaYydIQI2VWuw6FqcG8GiICTbJnuymoUxpjF2hgjYVKVX2V1zpWaRJ2y1NJQxJg12hgjYVrMoyZE2i1AeW2v9YJEbjfrGmOaxYBHgt1nkShoqP0+oDscAa7MwxjTOzhABfs0ilxq4fZaGMsY0xs4QAZuqdP7tXBl1NjjhkdUsjDGNsTNEwKbqMF2L87N+/m1ffmA8KGuzMMY0xoJFwKaqMKU50l4BddNQVrMwxjTGzhABW2qidCnKjZ5QYGkoY0z67AwRUFkboXNR7qRjQnnWwG2MSY+dIQK21kToVJhDNYuQ1SyMMemxM0TA1trcSkPVbeC2r4IxpmF2hgiorInkTLdZ0CHKfYU2n4UxphF2hgjYUhOhcw7VLPw0VGF+Xs50FzbGNI8FC49zjsraaE42cBdZrcIYk4KdJTy1UW+WvBxs4C4qsK+BMaZxdpbwbK3ReR0652CbRbDtwhhjkrGzhMef1yGX2iz83lB51lxhjEkho8FCRMaIyDwRWSgi1yZZP1BE3hSRT0Vkqoj0C6y7SEQWeD8XZbKcwLYZ43IpWMTTULlTmzLGNE/GgoWIhIB7gBOAYcD5IjIsYbO/Ao845/YFbgFu9fbtCdwEHASMAm4SkR6ZKiuwbRKgXOw6a/dYGGNSyeRZYhSw0Dm32DlXCzwFnJawzTDgLe/5lMD644HJzrn1zrkNwGRgTAbLSqXXZpFLDdx+GqokhwKkMaZ50goWIvKCiJwkIk0JLn2BZYHX5d6yoE+AM73nZwClItIrzX0RkbEiMkNEZqxZs6YJRauvOqzBoiSHUjJ+zaLYhic3xqSQ7sn/H8AFwAIRuU1Edm+lz78aOFJEPgaOBJYD0XR3ds6Nc86NdM6N7N27d4sKUuUFi+Ic6kbq1yxy6ZiNMc2T1lnCOfeGc+7bwP7AEuANEXlPRC4RkYYmgFgO9A+87uctC77vCufcmc65EcCvvWUb09m3tVVvCxa5c5VdsC1Y5M4xG2OaJ+1LSi89dDFwGfAx8H9o8JjcwC4fAkNFZLCIFALnARMS3rMskNq6DhjvPZ8EHCciPbyG7eO8ZRlTHYkBuXXijOoh59QxG2OaJ63WXBF5EdgdeBQ4xTm30lv1tIjMSLaPcy4iIlegJ/kQMN45N0dEbgFmOOcmAEcBt4qIA/4LXO7tu15EfocGHIBbnHPrm3WEaarJwTRUVQ7WpowxzZNu1587nXNTkq1wzo1saCfn3ERgYsKyGwPPnwOea2Df8cRrGhlXVZt7J85cDJDGmOZJ9ywxTES6+y+89NCPM1SmdlEdiZKfJxTk0KB6udhOY4xpnnTPjN/3Gp4B8O59+H5mitQ+qsOxnDtpdutUCEDf7iXtXBJjTEeXbhoqJCLinHOw7e7swswVq+1VhaM5l465YNQAuhbnc8q+fdq7KMaYDi7dYPEa2ph9v/f6B96yrFEdjuZczSKUJ5w2vN69jsYYU0+6weJXaID4kfd6MvDPjJSondTkYBrKGGPSlVawcM7FgHu9n6yUi2koY4xJV7r3WQxFR4QdBhT7y51zQzJUrjZXHY7m1LhQxhjTFOleSj+I1ioiwGjgEeCxTBWqPeRim4UxxqQr3WBR4px7ExDn3FLn3M3ASZkrVturCscostFXjTEmqXQbuGu8MZwWeEN4LAe6ZK5Yba/G2iyMMaZB6Z4drwI6AT8BDgAuBDI+1WlbqgpHc2qWPGOMaYqUNQvvBrxznXNXA1uASzJeqnawtSaSU7PkGWNMU6SsWTjnosBhbVCWduOco7I2Suciq1kYY0wy6V5KfywiE4Bnga3+QufcCxkpVRurjcaIxJzVLIwxpgHpnh2LgXXA0YFlDsiKYFFZo6OvdrY2C2OMSSrdO7izsp3Ct7U2AmA1C2OMaUC6d3A/iNYk6nDOfa/VS9QO/ImPOlmbhTHGJJXupfQrgefFwBnAitYvTvvYWuunoaxmYYwxyaSbhno++FpEngT+l5EStYPKGj8NZTULY4xJprm3LA8FdmjNgrQnv2ZhbRbGGJNcum0Wm6nbZvE1OsdFVqj0G7itzcIYY5JKNw1VmumCtKetNdZmYYwxjUkrDSUiZ4hIt8Dr7iJyeuaK1basZmGMMY1Lt83iJudchf/CObcRuCkzRWp7lV6bhU1+ZIwxyaUbLJJtlzU5m+pwlPw8oSBkQ5QbY0wy6Z4dZ4jI7SKyi/dzO/BRJgvWlqpsljxjjGlUusHiSqAWeBp4CqgGLs9UodpadThmwcIYYxqRbm+orcC1GS5Lu7FZ8owxpnHp9oaaLCLdA697iMikzBWrbVVHLA1ljDGNSfdyuszrAQWAc24DWXQHd1Vt1HpCGWNMI9INFjERGeC/EJFBJBmFdnulbRaWhjLGmIake4b8NfA/EXlURB4D3gauS7WTiIwRkXkislBE6rV5iMgAEZkiIh+LyKcicqK3fJCIVInILO/nvqYcVFNVR6IMYTnc3A2WZ00nL2OMaTVpBQvn3GvASGAe8CTwC6CqsX1EJATcA5wADAPOF5FhCZvdADzjnBsBnAf8I7BukXNuuPfzw3TK2VxVtVH2CX+mL6bdk8mPMsaY7VK6AwleBlwF9ANmAQcD06g7zWqiUcBC59xi7z2eAk4DPg9s44Cu3vNutNMcGTWRGAWFXtxc9XnjGxtjTA5KNw11FXAgsNQ5NxoYAWxsfBf6AssCr8u9ZUE3AxeKSDkwEb2fwzfYS0+9LSKHJ/sAERkrIjNEZMaaNWvSPJT6qsNRevjt9xu/Apc1zTHGGNMq0g0W1c65agARKXLOzQV2b4XPPx94yDnXDzgReFRE8oCVwAAvPfVz4AkR6Zq4s3NunHNupHNuZO/evZtdiKpwlG7+0FfhrbBpebPfyxhjslG6waLcu8/iJWCyiLwMLE2xz3Kgf+B1P29Z0KXAMwDOuWnolK1lzrka59w6b/lHwCJgtzTL2mTV4Shdo4GK0uovMvVRxhizXUq3gfsM59xG59zNwG+AfwGphij/EBgqIoNFpBBtwJ6QsM1XwDEAIrInGizWiEhvr4EcERmCzsy3OL1DahrnHNXhGKXRDbDj3rpwtbVbGGNMUJNHjnXOvZ3mdhERuQKYBISA8c65OSJyCzDDOTcB7VX1gIj8DG3svtg550TkCOAWEQkDMeCHzrn1TS1rOmoiMQA6RTZAr/00BbVhSSY+yhhjtlsZHWbcOTcRbbgOLrsx8Pxz4NAk+z0PPJ/JsvmqwzqXRWGsBgpLoftA2JAqw2aMMbnFblsGjtq9NwWEIVQAPQbCmrkw5Vaorki9szHG5ICcDxbdOxXy0CWjKCICoULoMUhTUW/fBrNfaO/iGWNMh5DzwWKbaC3kF0Kf/ePLKte2X3mMMaYDsWDhi9ZqzWKv0+HaZdC5t7VdGGOMx4IFQCwGMS8NBVDcVdNRGy1YGGMMWLBQ0Vp9DBXEl3UfCOuXtEtxjDGmo7FgAYFgURRf1mc4VHwFm1a2T5mMMaYDsWABEA3ro5+GAhh8hD4ueafty2OMMR2MBQuAaI0+BtNQO+4DBZ1h+cz2KZMxxnQgFiwgnobKD6Sh8vL0Br2NS2HzKhu23BiT0yxYQPI0FGgj95J34fY9YN6rbV8uY4zpICxYAESSpKFAaxY1FeBisHxG25fLGGM6CAsWkLw3FGjNwteSOS6iYXj8HFj2YfPfwxhj2lFGR53dbmxLQyXULIadBltWwdoFsHpO899/41ewYJIGnJ991vz3McaYdmI1Cwj0hkpos+jWF479LfQZoXNc1GxJvv/ahbB4asPvX7O57ucYY8x2xoIFJO8NFbTDnvr46VPJ199/ODxyGkRqk6+v8uZtilQ3v4zGGNOOLFhAw2konx8s/vMLWD1XnwdrGeFKfVwxE8JV9fev9IOF1SyMMdsnCxYQ6A1VmHx9j8Hx55tXwGfPwa19YdUcCAdqCx89DH/YCWYnTPJXtaHu5xhjzHbGggUEahYNpKHy8uDs8fp8yxqYeI0+/+p9eOys+HaL3tTHxEmT/JoFLv5ZxhizHbFgsflreOEyfd5QGgpgl2P0seKreBvE8o9g6bs6nHlpH6jaqMsTaxD+9gDjx8CW1WmUaxU88914rcQYY9qRBYuSnvHnDaWhAIq7QV4BLH0vvmz284CD0+7RgOH3dtr8Nbz9F4hG9HVlIFgsnwF/HQrrFjVerld/CZ+/DAsmN+VojDEmIyxY5AcCREO9oQBEdPa8L/+rr0d8B0p6QN+R0O9A6FwW33bVZzDl97D0f/p6y9f1U1xTb63/GUvehYrl+nzFzNRlMsaYNmI35QU1loYCDQibV0B+CZz897rbd+5df/tFb8Ggw3V61gEHw5dvx9cVd6+77frF8NCJMOAQuORVvZEPoHpT847FGGNakdUsAPY6Qx/zixvfrmtffew3sn5gSRYs3v0/mDEeKsp1n+D71Hpdb53Tn5mP6uuNy+q2adRYsDDGtD8LFgBnPgA/m5O6ZrH/d/Vx5/3qr+uSJFgAzH0FXFTbNHwlPaG6QoPEb7vD5N/AuoW6rmoDrJod39a/+9sYY9qRBQvQINGtX+rtdj8Bzn8Kjrqu/rpeu8afX/Iq/PgDbTD3hwHpPhDGvg1XfQol3bXnVLXXe+q9u3TeDIDwVpg/Kf5eU2+FBW8067AA+PCf8OzFzd/fZF71JnjwxMaHjDG5Yc6L8OgZeiE5dyLcPgz+9/f2LhVgwaJpRDRgFHWpv26HYfHnA78BO+wB+3xLX3fqBX0P0Hm9ewzUnlXVG7XXlG+8szhBAAAc5ElEQVTlJ7Dj3vp80ZtQ1C2+7oXv1/+8inKYcCXUVsaXff0ZPHsJvDAWXvwRLH5b7zqf86LdENiRfXCfdsGe9o/2Lolpb89erG2dW1bDJ0/CpuUw9TbtSu978xYob/spEyxYtJZkbRb7ngP9D4YT/lw3wBR31zTUphV1t/eDxbqF0GNA8s9ZNAW+fAcm3wgzH4F5E+Pr3r0T5rwAnz4NnzwBj5waX1dR3rzjWvJu/SveSC1Mu0eveN6902YRbKnPX9bHBZNg0q/h02frro/F9Hc985G2L5tp2Bf/hhUfZ+a9P3wAvpigg5hGqmH+a7p8yxp452/wyOmZ+dxGWG+o1iICe5wcbwQHGHKU/iQq7qZpqGDNIlQEB16mJ/toraatvk4YznzZh/DsRSAhKN3JWzYd9jlbn5ck9LAK2rBEu/qu/xL6HZD6eCrXw+rP4aGT9PXNFfF1CybBpOvjr/c4CXrt0vj71WzR2Qb7H1i3/aalFr0Fklf397xlDWxeCTvv23qfE7RmnnZpbo3j2Lq2bhvV+/fqY58RUOalNsunwxs36/N9z2397tTRsN4/NPgI/R6b1CK18PSF+vx7k/RCL1nGoanySyBSBf/9i74e/Wt4+XL49BlNled5p+x2GJTUahat6bzH4cQ/p96upLu2TfjdY3+9Cn6zWk+kfttJ8ERUtV4bvv/1Ta2RVHknctC7yLdtt0H32+Pk+p+5cSk8MBr+eXR6jeav/CweKIK2rNH5PYI2LEn+HrGYbh+u1i//C5fBy1ek/mzQMiYblLHO5y7V/O4jp+lV3tef6Y2Qz1+qIwH796yk+3m1WxteX12hAXT5TLhnFPzffvVrhkn326R/F//GzPWLYeWn8RGK/ft2hnsnnssmQ14IPnpQX29dBwvfjL/flkA6orV8cL/WQj97NvW228qxOvdqlP4x126FxVPiy8cfrzfRgq7fsia+rmYzrPrc+19IMXJDpLbuNAajfw1Dj4Xdjtd7th47U9sgAQo76XcpeMGZYRkNFiIyRkTmichCEbk2yfoBIjJFRD4WkU9F5MTAuuu8/eaJyPGZLGebK/baI9Z8oVf7BYEuu36QKBtaN7X1UCAAdPUCyuAjYGvgC1i5XntafethON676W/IUdolePYL8ZN68C70hlQHahJ+eWs2w193hTd/C112hCu9Gwf9xvlEL47V7Z/+Nrx7hy5b9kHqIABwaz8Yd1Tj2yx6K/786QvhvsPgjZvigfTDB1J/ju8vu8K9hza8/s794c+DNeD67h6lv/PGTpp/HgJ/GqT7LnxD3+f+w/V3CHrSKSyFU+6A61do21b/gzT1F4vBX4bAfwMXIBXLW/8kvewDfZzxYHrbVyzXUQjevKV1y9GRrVukxzz9AR0P7olz6q73v3PTx+l3fv1iff3Md+HeQ+CZ7+j+S6c1/BkVy3QKZz87MfgIfTzp73DFR/o/98UEXVZdAXeOgLsP1ODkjxaRQRkLFiISAu4BTgCGAeeLyLCEzW4AnnHOjQDOA/7h7TvMe70XMAb4h/d+2cG/IW/lp3WnbgU4/V644FnY73y4fLp+SXbcJ56qGPMn+PF7cPmHsNO+msbwVa2HTj0hlA8jv6fvc8b9erf5knfi2z1xjl6VN6agRFNjB/1Qr45jMU1h+XbaV0fjDRUmr1lUV8SvVBd6vbnyizXFVp5ieln/ZLhmbsPbLJ8Jr/xU/4GumAHnPQG7nwjT7oat3pXdoikw5Y9wz8GNn2CrNmq1fsOXydfHYlDp/Z6Hfxu+9zqcdDvUbtYg8NvucMe+9WsmW1ZDLDBw5GNn6Y2dfUfq7+Tjx7UdYtCh2iOvsLNuN/hI/Xs/elp834Mv18cHx8CT5zV8LE0VroYl3kgDX3+WXiDy/y7/u11TJH/bQ0dibszit+Hmbs1vO2tvfkp4+jj4yjvhDz0uvr7QS0HN/Y8+LnhDa5/+Bc3cV/RxYSM9G/2pm7/1MHx/it7IC/r/XLar9rI87wkY9YP4PjWbNDiNz/z1dCbbLEYBC51ziwFE5CngNODzwDYO6Oo97wb49frTgKecczXAlyKy0Hu/RsLydsRvW9jwpU7dGlS6U7w9Ir9IT/6H/VRTKwDDTtUr/eJuWvMIV+pJqrCzXuX2GqrbFRTDbt6X+Yir4eNHoVMZHPoTrTJPul5z1ec/paPqJqqu0GFMug8AnH4p/aAw7HQ44hrdr1v/eOCprdQ2lWNuiqfYfD0GwZn/1FTahqUwGB1b64t/w1n/0hP76zfAIZfX/ScETeM88129ghp9vf4O/H/Kk+/QWljZUOg3SlNk6xZob7KVn8DKWbrd3QfCYT/Tbsouqu0+oXztJRYcZv7RM2C/C7SaP+sJvZly5ae6rs8IDRIFxTDgIK0VfvgvTRFsXKonh9HXa1oH6ga7Ljtpm9TgI/Rk88ZN8PKPdd2xCVfoB14K0++Pp6gOuETL/v49+nr+a5p6u/DF5H+7ZGY+osdTXaF573MegZ6DYebDepGx15naXlZRDt3760ntg3FwzsN64QAaSF4YG691FpbCx4/p8+cv1e/hARcl//zp4/Rx6TTY91vplbkjWTNPH9d5Kdg9ToZT79K04KNn6MXY3QfC2vm6fvKN2vYAUNQ1fnOtX4tLxq+d7LBn8vaPXrvoz8BDoWsf7XW5eSWsmQ9dd275MaaQyWDRF1gWeF0OHJSwzc3A6yJyJdAZ+GZg3/cT9u1LAhEZC4wFGDCggd5DHVFxoFtsYs0imV2PiT/vslP8uZ+m2rJa//GrNmhwSVS6E5x6t+bC9zoD3rs7fqUTqdYTY6KqjfqeflmrK+LpplPu0BMl6JfWz6OvnAULXtegMmS01jr8WQiPuj7e4Lx5paainvuevnaxeI+gCVdAt8Df8uvZmqv1P+P5y2DZ97XHV79RsMeJ8W279IaxU7Sr4T5na2Px0ve0er9ugb53USnscjR88Ype9e+wF/TbS6/s1y/SK8Fgesv/PQGMvqFuynDvMwEXHwNs6xpt6+nWXz8TtLbTY5AGV/9v032A3j8TqdbfU+/d6/7uO/WE4/8Y7zJ93O/iV66+xVO1W2X3/jRo7kQdYqa4O7x9my7Ly4dYRNMZh16lx7fj3jBqrAaLl36kaZBFb+rxzHhQc+YzH9ba7mfPeO9TAJe/D2/+Tn8nHz2k+fRgsHj7z/oe/QP/9k0dkeC9u7QmNvCQustnPaEn4T0D6dnNq3TUhNHXt05jc9DqOXVfn3Gffpc69dST9uznIRaNr999jJavqBT2PFWD5dp52iElXBUPwHU+43P9rqQqe0l3vYBsY+3dG+p84CHn3N9E5BDgURHZO92dnXPjgHEAI0eO3H5a24LjQvVII1iU9NCT/def1r2S9IPFRw/B0TfoP6J/Ek8UvJrbeV8dah30KjuZ6gqvBuOVdc6LehIt7lb3Mzr31nJBvMF37Xz9x93teB26vXw6DD5ca0olPTVY+KkPiAcKX0WgVvLSj+o26kZrNNUEWgtJVFQKx/9Bn585Tmtbf/Ymr3IxPXmfcZ+2JVSug2/epOWsroDHz9EJrWq9DgAFnfVk7NcQkvV+Gnoc7HqsztU+f5KmY074k6YU1syFk2+vv0/XnXWk4ucvjQfTRLt+U4NhzyF6TKDphz7D4d9X6X4blzYeLJ46P8nvpyt02UHTQqN+AF99AKO+r6MSDDxMLzz8lGVpH+2muW6BDlsTDKKlO2tnjDO9WlTXfjDlD/r77tRTa49TvL/D9HFaKwMN5HudkfyiZul7UNBJjxG0bK/foLXvdQv1+7Ov11bw0o/08VdL4t/H6eO09vXVNPj2s3UH92yp1V/od6eoVAO8/zcBTdXWVurvYsKVOtLDrt+su/+Ag/T78cQ5GjCGHBlft2Y+zP23rh9yVOuVuZVlMlgsB4Lf5H7esqBL0TYJnHPTRKQYKEtz3+1XnZrFoPT22f879Zf5/wzv3qG5dNAcfirBq9RkkzFtWgGbyjVQ+GV94yZ9HJBwhde5d7yNINjQXVMBR14LOyXE/q59YP7rWnMJFer7+QMsHnMTvHcn7HaC3icC8UA08nuw91mafolF9CR6YJKbFRN16ql31/uNxsO8/ukn/FlrAQO/oa+Lu8GlkzQl9Qfvd/iLL3T5x4/Bf//qpeQSFJXChV6+fse94PCf6/PBhzderiFHaZffb/yk4XJfljA8vd/Trv9BcNf+ekIedFjdbTZ+laLtwemJbNrd8NqvNPgOPkJrl5d4qb0JP9Ha4dG/0bThDG/ir2BXbr/x1Tf0mzrS8sePao0lOGgmxO9H2LpaT6jnPa6/67Xz9eKlcj08ca6mWcZO1W3f+p0+zp0Yv6AYemzdY/viFdhltHa++NgbX23FTP2+nnZP8l/Bl+/ojbI7Jjahou+9Yib02V+7EVdt1P+HdYs0aB19Q/19+o+CC57S5+c0ci/MwG9o+nPGv/Q73GUH/Q48drYOUArxKZw7oEwGiw+BoSIyGD3RnwdckLDNV8AxwEMisidQDKwBJgBPiMjtQB9gKDA9g2VtW8H7IVrSVz948vJv2knny+Y3pELdqrPvdu89irvVv3fjsJ/Xfd25t16VR2r05JVfoieg3cbUDxSg220qhznlmg7a9zw9sYx9W68o/ZPtaffALd4V45HXwmhviJUbVus/WFPuB7jyo/rL9jk7fn9KUEGxpgb9mhXAiAv1pzV1LoObmjmxVbf+gNTvhRYNw8On1O1wcOpdenL27X+RXgl/cJ/WSKH+BcCpd8af734SzPuP1p4WTtYa7vAL9G8Q1GeEBsAPxmkA/Op9bSO7ZiH8+yd1byic+4quf/8fGgQufF5P4DWbtJ2paoN2GV7yjqZdtwS6h65bXLfmOf81TS/6DrlC03szHoTj/qB/w3Bl/Ds/71XtIJBfDNcu0yATyo//rT95Cl76IVz0bw2Ij5yqZYKWn8iLSqFsNz3mxNq0r3cOBgvnXERErgAmASFgvHNujojcAsxwzk0AfgE8ICI/Qxu7L3bOOWCOiDyDNoZHgMudayhfsh3KL/by+eHG0wipdC6Dcx/Xrql+sOi9R+r96gSLhJpFLBZ/HsrXf3jfjz/QYUwSywDaK2vdIg0QFzxT9zOCuvXVtMbFE/WKsqhUrwy77FB3u7w82Hm4toMceGlgeRt0ivvxNE1ZdVT5hdqukNij7eNHNVCcepd2GJjzgtZ2vvETrbF96yHNn+eFtKfdXftrI3Vx12Sfos76p3YD7b2H9ggr3anhbYedprW1dYs0nbfTPhrUT/yrpry699fvyX2H1e29409N3HsPTd3Ney2e0x9+gfa68j1+dnzmyUGH121T2vNUrZ2WT9f2k6Xv6bA6E3+pPQi79oO3fq/bRqq13eb5SzU1d403GdnUP+rjyk/0/f1AAdq+1VIDDtYu80Gn3Kk1rGl312+/6kAy2mbhnJsITExYdmPg+edA0s7tzrk/AH/IZPnajYimePLyW343rj/0+dJ39QTS2F3cvmAaKpbQP3vjkvjzSI3m1y98XmsMiYEC4u0mFeU6C+DI7yXPR/vO/KdeKe60T3xZYqDwXfCMprgaWp8pDQW6jqRrn3jqYu1CrVFsXqEpqhHf0R5dB1ys923sPEI7SQw+Ml4j67WLdssOpTgFFHaK1xAbCxSg7w9678iaefEgn18Uf4/ibnDxK5qnz/NGInj4FF137uPam+6lH+r/h+TBN66sGyyq1mtvoCOu1pP34inaZhEq1OX5hdqLL79EO1vkF2kb1Nt/1nHdVs2GE/4Cr14T72FYs0m/u+sXaxpPQtpGkTibZWucyI/7nXYU6N5f71eJVGvKMhrWNpFMjTrQCtq7gTt3lXTXvGlLddlRayqRav0nSUfwZJjYZuH39d7vfP1HhfqNdXU+3zuRfzHB++If2fC2oD2WGhrOPVHpjvpj6uu6s94ZvGy63mnvN5Qf/RsNCKH8eCNqXl7yhlN/OJHW0nOIXrDMeFC7jTaUtul7gP74vj9FT9Jlu2rngyfO1Z5ePXfRC49LXtNU0mNn6vb7nqMpTID9ktxzkl8E+5ylPab8Msx6Qu8TKuqmFzSgAQMA0cb7NXM1xddrF60Z+e0uR/xSh1lpjaFQikq1sRs04PtCBXq/TQdmwaK9HHJFerWAVES07WLt/HhjbSp10lAJNYtVXl/vE/+aXvfD3nvoP+AH9+kVWbplMC1TurMOA/LatRoohp2m+fBUDeuZJKIXC588od+FQWmWpe/++gNa4/zuyzqgot8t2u82e8xNOrzNHqekfs+DL9eOCStn6UXUqjnaxXn3kzSQHjTWq9U7+HyCpq2iEf09dtlBazP/maXBb/T1NmYWFizaT0M3LzXH2eO1EXPPNP6JoPE01OrPtYE33X7qxV21BjLl9/pP2Vj+27Se0p11tsXlH2kbhT8xV3vb91t6M+HwC9LrFp5M2VD49jP1lx/+8/rLGrLDnlrr3rJKv5fDTtP7boI1Ef9/sM8IHS4mFot3evBTXwdcbIHCY8EiG+y0T7y7YTpSpaF2SNKlsDEH/1Bv2ko3WJmW81MYPXfR9omOYpej4edzUm+Xaf7cMx89pN1g9/1WPK2aaOf94KeBbsHhKm30/saVcOQv26S42wMLFrkoWGsIdp11Tm9+8ocJSfv9SuGqT9qmp5JRPb0h4Y/+depG6lx18h06lErwvqZ0FJTozX72fa7DvmW5qKGus5FqfV3cjLYU+8dqW/0O0FF/U80jkstEmh4ofPZ9rsfms8hFocL482CbhT9F6/bQddRYoDBtyoJFTgo02EXD2k9/0q8DYyIlGVjQGJPTLA2Vi3bYE8p211EwYxF47mId98e/TyPZKLTGmJxmNYtclBfSm59Ag4U/zo8/IGCBpaGMMXVZsMhVoQJ9jIbjaSd/1j2rWRhjEliwyFV5XgYyFokHC3/eCKtZGGMSWLDIVXlezSIWiY/w+dGD+mg1C2NMAgsWuSoUqFkkdpW13lDGmAQWLHKVn4aKhuvPB2z3WRhjEliwyFXb0lDh+hP9WM3CGJPAgkWu2tbAHa0/mGBiTcMYk/MsWOSqUCAN5U+c47MhmY0xCSxY5Kpg19lorU6glG81CmNMcjbcR64KtllEwzqP8WVvQeXa9i2XMaZDsmCRq7b1hvJqFqHCps2PbYzJKZaGylV5eTomVCyiNYvgsOXGGJPAgkUuyyvw0lC18bGijDEmCQsWuSwv3+s6W2s1C2NMoyxY5LJQvqagIhYsjDGNs2CRy/Ly411nLQ1ljGmEBYtcVqfNwmoWxpiGWbDIZaECr+ts2GoWxphGWbDIZUWlULPJq1kUtXdpjDEdmAWLXFa6E2xaYfdZGGNSsmCRy0r7wIYlUFNhaShjTKMyGixEZIyIzBORhSJybZL1fxeRWd7PfBHZGFgXDaybkMly5qzSnaBqvT63moUxphEZGxtKRELAPcCxQDnwoYhMcM597m/jnPtZYPsrgRGBt6hyzg3PVPkMGix8W75uv3IYYzq8TNYsRgELnXOLnXO1wFPAaY1sfz7wZAbLYxpTUd7eJTDGdGCZHHW2L7As8LocOCjZhiIyEBgMvBVYXCwiM4AIcJtz7qUk+40FxgIMGDCglYqdQ/Y7D9Z/CXkh2P+77V0aY0wH1lGGKD8PeM45Fw0sG+icWy4iQ4C3ROQz59yi4E7OuXHAOICRI0e6tituligqhTF/bO9SGGO2A5lMQy0H+gde9/OWJXMeCSko59xy73ExMJW67RnGGGPaUCaDxYfAUBEZLCKFaECo16tJRPYAegDTAst6iEiR97wMOBT4PHFfY4wxbSNjaSjnXERErgAmASFgvHNujojcAsxwzvmB4zzgKedcMI20J3C/iMTQgHZbsBeVMcaYtiV1z9Hbr5EjR7oZM2a0dzGMMWa7IiIfOedGptrO7uA2xhiTkgULY4wxKVmwMMYYk5IFC2OMMSllTQO3iKwBlrbgLcqAta1UnO2FHXNusGPODc095oHOud6pNsqaYNFSIjIjnR4B2cSOOTfYMeeGTB+zpaGMMcakZMHCGGNMShYs4sa1dwHagR1zbrBjzg0ZPWZrszDGGJOS1SyMMcakZMHCGGNMSjkfLERkjIjME5GFInJte5entYjIeBFZLSKzA8t6ishkEVngPfbwlouI3On9Dj4Vkf3br+TNJyL9RWSKiHwuInNE5CpvedYet4gUi8h0EfnEO+bfessHi8gH3rE97U0TgIgUea8XeusHtWf5W0JEQiLysYi84r3O6mMWkSUi8pmIzPJmEW3T73ZOBwsRCQH3ACcAw4DzRWRY+5aq1TwEjElYdi3wpnNuKPCm9xr0+Id6P2OBe9uojK0tAvzCOTcMOBi43Pt7ZvNx1wBHO+f2A4YDY0TkYOBPwN+dc7sCG4BLve0vBTZ4y//ubbe9ugr4IvA6F455tHNueOB+irb7bjvncvYHOASYFHh9HXBde5erFY9vEDA78HoesLP3fGdgnvf8fuD8ZNttzz/Ay8CxuXLcQCdgJjrX/Vog31u+7XuOzi9ziPc839tO2rvszTjWft7J8WjgFUBy4JiXAGUJy9rsu53TNQugL7As8LrcW5atdnTOrfSefw3s6D3Put+Dl2oYAXxAlh+3l46ZBawGJgOLgI3OuYi3SfC4th2zt74C6NW2JW4VdwC/BGLe615k/zE74HUR+UhExnrL2uy7nbGZ8kzH5pxzIpKV/aZFpAvwPPBT59wmEdm2LhuP2zkXBYaLSHfgRWCPdi5SRonIycBq59xHInJUe5enDR3mnFsuIjsAk0VkbnBlpr/buV6zWA70D7zu5y3LVqtEZGcA73G1tzxrfg8iUoAGisedcy94i7P+uAGccxuBKWgKpruI+BeDwePadsze+m7AujYuaksdCpwqIkuAp9BU1P+R3ceMc26597gavSgYRRt+t3M9WHwIDPV6URSi84FPSLHP9mwCcJH3/CI0p+8v/67Xg+JgoCJQtd1uiFYh/gV84Zy7PbAqa49bRHp7NQpEpARto/kCDRpne5slHrP/uzgbeMt5Se3thXPuOudcP+fcIPR/9i3n3LfJ4mMWkc4iUuo/B44DZtOW3+32brRp7x/gRGA+muf9dXuXpxWP60lgJRBG85WXonnaN4EFwBtAT29bQXuFLQI+A0a2d/mbecyHoXndT4FZ3s+J2XzcwL7Ax94xzwZu9JYPAaYDC4FngSJvebH3eqG3fkh7H0MLj/8o4JVsP2bv2D7xfub456q2/G7bcB/GGGNSyvU0lDHGmDRYsDDGGJOSBQtjjDEpWbAwxhiTkgULY4wxKVmwMKYDEJGj/NFTjemILFgYY4xJyYKFMU0gIhd680fMEpH7vUH8tojI3735JN4Ukd7etsNF5H1vPoEXA3MN7Coib3hzUMwUkV28t+8iIs+JyFwReVyCg1oZ084sWBiTJhHZEzgXONQ5NxyIAt8GOgMznHN7AW8DN3m7PAL8yjm3L3oXrb/8ceAep3NQfAO90x50lNyfonOrDEHHQDKmQ7BRZ41J3zHAAcCH3kV/CTpwWwx42tvmMeAFEekGdHfOve0tfxh41hvfp69z7kUA51w1gPd+051z5d7rWeh8JP/L/GEZk5oFC2PSJ8DDzrnr6iwU+U3Cds0dQ6cm8DyK/X+aDsTSUMak703gbG8+AX/+44Ho/5E/2ukFwP+ccxXABhE53Fv+HeBt59xmoFxETvfeo0hEOrXpURjTDHblYkyanHOfi8gN6GxleeiIvpcDW4FR3rrVaLsG6JDR93nBYDFwibf8O8D9InKL9x7fasPDMKZZbNRZY1pIRLY457q0dzmMySRLQxljjEnJahbGGGNSspqFMcaYlCxYGGOMScmChTHGmJQsWBhjjEnJgoUxxpiU/h9wVgKfh33WtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['acc'])\n",
    "plt.plot(cnnhistory.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "acc: 85.42%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/home/vishnu/NN/model_CNN.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15165725, 0.03467991, 0.10866404, 0.18313482, 0.14526974,\n",
       "        0.27731758, 0.0992767 ],\n",
       "       [0.14368801, 0.09853927, 0.08647908, 0.07076237, 0.16260882,\n",
       "        0.32721946, 0.11070304],\n",
       "       [0.29135647, 0.13671218, 0.03087269, 0.12428001, 0.3159751 ,\n",
       "        0.04940001, 0.05140352],\n",
       "       [0.18531586, 0.11176945, 0.07695587, 0.08647907, 0.32831544,\n",
       "        0.11674894, 0.09441542],\n",
       "       [0.18468638, 0.15083055, 0.23085216, 0.0663793 , 0.10371275,\n",
       "        0.18692102, 0.07661778],\n",
       "       [0.17239648, 0.09827963, 0.15983377, 0.27095327, 0.09136198,\n",
       "        0.03871011, 0.16846478],\n",
       "       [0.0707662 , 0.01053482, 0.02882346, 0.09922901, 0.748533  ,\n",
       "        0.01864486, 0.02346869],\n",
       "       [0.11946622, 0.0929264 , 0.06139336, 0.13476036, 0.28527173,\n",
       "        0.06097357, 0.24520831],\n",
       "       [0.11764186, 0.11035454, 0.14021365, 0.14312112, 0.12161437,\n",
       "        0.19067824, 0.17637622],\n",
       "       [0.25635183, 0.07025652, 0.15550423, 0.1467635 , 0.1491078 ,\n",
       "        0.08146784, 0.14054829],\n",
       "       [0.06558824, 0.06271048, 0.14918873, 0.07693141, 0.08674986,\n",
       "        0.40263388, 0.1561974 ],\n",
       "       [0.08311694, 0.2834256 , 0.07392792, 0.1289025 , 0.09743585,\n",
       "        0.1898213 , 0.1433699 ],\n",
       "       [0.19531892, 0.11504015, 0.03009426, 0.045087  , 0.3468923 ,\n",
       "        0.05015163, 0.21741576],\n",
       "       [0.07969939, 0.2486904 , 0.07753608, 0.01397135, 0.29906243,\n",
       "        0.2710528 , 0.00998753],\n",
       "       [0.23420769, 0.03547017, 0.04983945, 0.09914585, 0.11927181,\n",
       "        0.04000592, 0.42205912],\n",
       "       [0.06780194, 0.0644929 , 0.07813695, 0.05884857, 0.5293695 ,\n",
       "        0.11801264, 0.08333752],\n",
       "       [0.3145713 , 0.08210164, 0.07124615, 0.14706834, 0.18263316,\n",
       "        0.08609752, 0.11628189],\n",
       "       [0.15384619, 0.07103102, 0.23170339, 0.24540596, 0.13247597,\n",
       "        0.10649931, 0.05903817],\n",
       "       [0.29132566, 0.0918374 , 0.05349506, 0.1380878 , 0.04408883,\n",
       "        0.2079095 , 0.1732558 ],\n",
       "       [0.30263844, 0.08786912, 0.26781777, 0.07740912, 0.15538274,\n",
       "        0.06069146, 0.04819127],\n",
       "       [0.13581848, 0.062341  , 0.03764163, 0.1442599 , 0.07562371,\n",
       "        0.06454422, 0.47977105],\n",
       "       [0.07086997, 0.14291301, 0.24943878, 0.12442209, 0.1108329 ,\n",
       "        0.09229326, 0.20922999],\n",
       "       [0.09049289, 0.05843553, 0.26029438, 0.05384344, 0.33639285,\n",
       "        0.06576858, 0.13477224],\n",
       "       [0.07050058, 0.06467672, 0.13412689, 0.26414618, 0.24407166,\n",
       "        0.10853718, 0.11394078],\n",
       "       [0.1525247 , 0.11104981, 0.04729549, 0.06002684, 0.40359005,\n",
       "        0.1521901 , 0.07332293],\n",
       "       [0.16693681, 0.03778837, 0.05545884, 0.20609984, 0.38882482,\n",
       "        0.05592848, 0.08896279],\n",
       "       [0.17803557, 0.22640531, 0.19164488, 0.13650143, 0.0315198 ,\n",
       "        0.13122468, 0.1046683 ],\n",
       "       [0.33068234, 0.10103028, 0.05893419, 0.10248806, 0.14414264,\n",
       "        0.07158482, 0.19113773],\n",
       "       [0.25274685, 0.0998794 , 0.04126339, 0.12045412, 0.22333592,\n",
       "        0.135031  , 0.12728937],\n",
       "       [0.1602685 , 0.14939378, 0.08601692, 0.05743023, 0.36436304,\n",
       "        0.11370961, 0.06881781],\n",
       "       [0.39097932, 0.02157607, 0.02725503, 0.07395153, 0.05803892,\n",
       "        0.32741013, 0.10078897],\n",
       "       [0.33034056, 0.07078338, 0.21276061, 0.09545992, 0.02441594,\n",
       "        0.2266181 , 0.03962156],\n",
       "       [0.13225958, 0.06596914, 0.21532965, 0.13152811, 0.30907524,\n",
       "        0.03572034, 0.11011787],\n",
       "       [0.12127416, 0.0979723 , 0.07099665, 0.13552949, 0.37617117,\n",
       "        0.1300772 , 0.06797902],\n",
       "       [0.13760163, 0.19490907, 0.1540941 , 0.10275426, 0.30499235,\n",
       "        0.04611038, 0.05953828],\n",
       "       [0.13955484, 0.23766308, 0.10101321, 0.08838177, 0.16177756,\n",
       "        0.14853126, 0.12307834],\n",
       "       [0.2037618 , 0.09329472, 0.06791005, 0.07522145, 0.318388  ,\n",
       "        0.15713565, 0.08428844],\n",
       "       [0.29353052, 0.14039679, 0.13251571, 0.10547705, 0.21656205,\n",
       "        0.07875028, 0.03276766],\n",
       "       [0.20380843, 0.14344925, 0.10402697, 0.04074046, 0.09959413,\n",
       "        0.311575  , 0.09680571],\n",
       "       [0.14137858, 0.13361542, 0.07635958, 0.03019677, 0.46286577,\n",
       "        0.08123861, 0.07434524],\n",
       "       [0.17477202, 0.1410974 , 0.11273069, 0.12217101, 0.24781537,\n",
       "        0.11955687, 0.08185663],\n",
       "       [0.12345763, 0.07110351, 0.05804317, 0.12438762, 0.16452067,\n",
       "        0.00800482, 0.45048252],\n",
       "       [0.1770778 , 0.13483065, 0.15568468, 0.07951798, 0.30712315,\n",
       "        0.10145137, 0.04431443],\n",
       "       [0.08595678, 0.15263799, 0.2191642 , 0.06406603, 0.38611013,\n",
       "        0.03657982, 0.05548513],\n",
       "       [0.05958436, 0.25826675, 0.10586023, 0.06465484, 0.01548498,\n",
       "        0.4520982 , 0.04405066],\n",
       "       [0.1413797 , 0.1686357 , 0.10954943, 0.02861584, 0.29030153,\n",
       "        0.18538943, 0.07612828],\n",
       "       [0.07228947, 0.04007899, 0.39891678, 0.01971054, 0.07870459,\n",
       "        0.10137952, 0.28892013],\n",
       "       [0.2558789 , 0.08641328, 0.06914183, 0.19689634, 0.18605989,\n",
       "        0.14199603, 0.06361373],\n",
       "       [0.17081901, 0.08023211, 0.29217988, 0.1749451 , 0.12320965,\n",
       "        0.09440567, 0.0642086 ],\n",
       "       [0.19617583, 0.07693037, 0.11512896, 0.07101674, 0.0361428 ,\n",
       "        0.43642652, 0.06817875],\n",
       "       [0.25092492, 0.18169099, 0.15071777, 0.14106244, 0.0600431 ,\n",
       "        0.05737824, 0.15818252],\n",
       "       [0.14975828, 0.12134765, 0.08363517, 0.13301934, 0.20378405,\n",
       "        0.12700215, 0.18145336],\n",
       "       [0.14589939, 0.09851994, 0.20071985, 0.1524931 , 0.30141473,\n",
       "        0.03695113, 0.06400193],\n",
       "       [0.05895685, 0.10265116, 0.30099726, 0.28674346, 0.09290978,\n",
       "        0.03629141, 0.12145006],\n",
       "       [0.25984392, 0.07290991, 0.04485834, 0.06982931, 0.41712093,\n",
       "        0.09568729, 0.03975035],\n",
       "       [0.08502346, 0.17000273, 0.09198077, 0.2579734 , 0.1298237 ,\n",
       "        0.10068674, 0.16450919],\n",
       "       [0.35430792, 0.05707309, 0.06276035, 0.07196884, 0.08265252,\n",
       "        0.25819328, 0.11304402],\n",
       "       [0.15641195, 0.19959302, 0.09155417, 0.10283616, 0.25716633,\n",
       "        0.09287291, 0.09956544],\n",
       "       [0.08395663, 0.05490858, 0.19603173, 0.07239006, 0.01117207,\n",
       "        0.45432493, 0.12721609],\n",
       "       [0.2065052 , 0.11454242, 0.0696749 , 0.3158105 , 0.10461409,\n",
       "        0.09609727, 0.09275563],\n",
       "       [0.07112757, 0.39241755, 0.0622539 , 0.02769363, 0.30097553,\n",
       "        0.09024931, 0.05528253],\n",
       "       [0.3405769 , 0.08556049, 0.08426487, 0.05354448, 0.21490431,\n",
       "        0.06083718, 0.16031185],\n",
       "       [0.11056045, 0.08819506, 0.28761107, 0.11334249, 0.27401564,\n",
       "        0.03730243, 0.08897286],\n",
       "       [0.181434  , 0.24317037, 0.14589003, 0.0324058 , 0.29223493,\n",
       "        0.05548333, 0.04938155],\n",
       "       [0.10254567, 0.06317157, 0.07604501, 0.10178306, 0.09885839,\n",
       "        0.03407904, 0.52351725],\n",
       "       [0.22987433, 0.06401584, 0.12859878, 0.17678021, 0.12993494,\n",
       "        0.17006993, 0.100726  ],\n",
       "       [0.06517565, 0.09938783, 0.26186332, 0.02192343, 0.48171234,\n",
       "        0.02626968, 0.04366775],\n",
       "       [0.10564812, 0.18227525, 0.18847151, 0.20821698, 0.10603463,\n",
       "        0.10640319, 0.10295036],\n",
       "       [0.21025342, 0.14577055, 0.0742526 , 0.13151973, 0.24907033,\n",
       "        0.07729159, 0.11184177],\n",
       "       [0.10584658, 0.23782831, 0.19922188, 0.21652558, 0.03161049,\n",
       "        0.07720809, 0.13175905],\n",
       "       [0.07543307, 0.23240297, 0.13228239, 0.06473342, 0.32383433,\n",
       "        0.06354027, 0.10777351],\n",
       "       [0.17322128, 0.08221867, 0.0575574 , 0.15385509, 0.20289773,\n",
       "        0.15917228, 0.1710776 ],\n",
       "       [0.06242044, 0.0395274 , 0.1724543 , 0.03747965, 0.5322642 ,\n",
       "        0.01952284, 0.13633114],\n",
       "       [0.2716638 , 0.11734824, 0.03215938, 0.03130546, 0.0915744 ,\n",
       "        0.30738983, 0.14855888],\n",
       "       [0.25138122, 0.01990688, 0.03418198, 0.15503691, 0.07846457,\n",
       "        0.39259776, 0.06843062],\n",
       "       [0.26683646, 0.07143006, 0.09349496, 0.14015332, 0.1342214 ,\n",
       "        0.23707859, 0.05678521],\n",
       "       [0.13477333, 0.19958542, 0.20391141, 0.06742516, 0.25527287,\n",
       "        0.05011594, 0.08891588],\n",
       "       [0.2506031 , 0.03979627, 0.04918691, 0.09254637, 0.27111134,\n",
       "        0.11710613, 0.17964983],\n",
       "       [0.25238734, 0.06056074, 0.16575328, 0.1379663 , 0.16748495,\n",
       "        0.12601745, 0.08982984],\n",
       "       [0.1939516 , 0.1136438 , 0.145477  , 0.11655242, 0.25923058,\n",
       "        0.04634962, 0.12479501],\n",
       "       [0.13430408, 0.0444779 , 0.21022393, 0.1669038 , 0.02967847,\n",
       "        0.11131666, 0.30309516],\n",
       "       [0.14846522, 0.07248314, 0.05736984, 0.11217247, 0.33820114,\n",
       "        0.15384698, 0.1174612 ],\n",
       "       [0.07002205, 0.12366951, 0.09204334, 0.11285809, 0.0716133 ,\n",
       "        0.05946304, 0.47033063],\n",
       "       [0.49174523, 0.02738212, 0.03233584, 0.06638317, 0.0616629 ,\n",
       "        0.102917  , 0.21757379],\n",
       "       [0.34224743, 0.09215261, 0.13121459, 0.09552681, 0.04633394,\n",
       "        0.1305969 , 0.16192769],\n",
       "       [0.33305913, 0.03582463, 0.05334773, 0.11436316, 0.21853699,\n",
       "        0.19678721, 0.04808106],\n",
       "       [0.13890542, 0.1586448 , 0.16877241, 0.07900198, 0.16841204,\n",
       "        0.22631636, 0.05994695],\n",
       "       [0.26141596, 0.1591458 , 0.04576501, 0.06018201, 0.37163377,\n",
       "        0.03905065, 0.06280687],\n",
       "       [0.07952912, 0.26714885, 0.08254736, 0.035343  , 0.30074358,\n",
       "        0.16557443, 0.0691137 ],\n",
       "       [0.21859828, 0.07869214, 0.13675445, 0.11960851, 0.2787453 ,\n",
       "        0.07327197, 0.09432927],\n",
       "       [0.09098851, 0.01307299, 0.13729565, 0.29420808, 0.03212836,\n",
       "        0.09077846, 0.341528  ],\n",
       "       [0.10658037, 0.14225352, 0.07978708, 0.14678934, 0.3876041 ,\n",
       "        0.06562488, 0.07136078],\n",
       "       [0.09334321, 0.16690145, 0.01884973, 0.10674177, 0.34125438,\n",
       "        0.1663221 , 0.10658731],\n",
       "       [0.16765004, 0.23437077, 0.09616558, 0.0432883 , 0.11634742,\n",
       "        0.29112792, 0.05104993],\n",
       "       [0.10630766, 0.0584897 , 0.15617146, 0.0796313 , 0.00870595,\n",
       "        0.43926367, 0.15143028],\n",
       "       [0.40506956, 0.13212311, 0.06670029, 0.04442478, 0.04223625,\n",
       "        0.19719622, 0.11224988]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = np.argsort(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, 0, 5, 0, 3, 6, 6, 2, 6, 5, 6, 5, 0, 5, 4, 2, 5, 2, 3, 6,\n",
       "       2, 4, 0, 3, 2, 6, 4, 0, 5, 5, 2, 3, 1, 4, 0, 4, 0, 0, 0, 4, 0, 2,\n",
       "       1, 5, 6, 3, 3, 0, 1, 6, 2, 3, 0, 1, 5, 1, 2, 0, 4, 4, 4, 1, 0, 3,\n",
       "       2, 2, 0, 3, 1, 0, 2, 0, 0, 5, 2, 0, 4, 0, 2, 5, 1, 6, 6, 4, 2, 0,\n",
       "       1, 0, 3, 3, 1, 1, 2, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2[:,-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 4, 4, 2, 3, 4, 4, 5, 0, 5, 1, 4, 4, 6, 4, 0, 3, 0, 0, 6, 2,\n",
       "       4, 3, 4, 4, 1, 0, 0, 4, 0, 0, 4, 4, 4, 1, 4, 0, 5, 4, 4, 6, 4, 4,\n",
       "       5, 4, 2, 0, 2, 5, 0, 4, 4, 2, 4, 3, 0, 4, 5, 3, 1, 0, 2, 4, 6, 0,\n",
       "       4, 3, 4, 1, 4, 4, 4, 5, 5, 0, 4, 4, 0, 4, 6, 4, 6, 0, 0, 0, 5, 4,\n",
       "       4, 4, 6, 4, 4, 5, 5, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc2 = preds2.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = (lb.inverse_transform((abc2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2nd best predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2nd best predictedvalues\n",
       "0                         1\n",
       "1                         6\n",
       "2                         2\n",
       "3                         4\n",
       "4                         0\n",
       "5                         3\n",
       "6                         5\n",
       "7                         3\n",
       "8                         2\n",
       "9                         1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf2 = pd.DataFrame({'2nd best predictedvalues': predictions2})\n",
    "preddf2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictedvalues\n",
       "0                5\n",
       "1                5\n",
       "2                4\n",
       "3                4\n",
       "4                2\n",
       "5                3\n",
       "6                4\n",
       "7                4\n",
       "8                5\n",
       "9                0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualvalues\n",
       "0             1\n",
       "1             5\n",
       "2             5\n",
       "3             4\n",
       "4             5\n",
       "5             2\n",
       "6             4\n",
       "7             5\n",
       "8             1\n",
       "9             6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actualvalues  predictedvalues\n",
       "30             5                0\n",
       "31             0                0\n",
       "32             5                4\n",
       "33             6                4\n",
       "34             5                4\n",
       "35             1                1\n",
       "36             4                4\n",
       "37             2                0\n",
       "38             6                5\n",
       "39             0                4\n",
       "40             4                4\n",
       "41             3                6\n",
       "42             1                4\n",
       "43             3                4\n",
       "44             0                5\n",
       "45             4                4\n",
       "46             6                2\n",
       "47             1                0\n",
       "48             2                2\n",
       "49             1                5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = finaldf.join(preddf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "      <th>2nd best predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actualvalues  predictedvalues  2nd best predictedvalues\n",
       "30             5                0                         4\n",
       "31             0                0                         1\n",
       "32             5                4                         0\n",
       "33             6                4                         5\n",
       "34             5                4                         2\n",
       "35             1                1                         5\n",
       "36             4                4                         4\n",
       "37             2                0                         1\n",
       "38             6                5                         2\n",
       "39             0                4                         6\n",
       "40             4                4                         0\n",
       "41             3                6                         3\n",
       "42             1                4                         1\n",
       "43             3                4                         5\n",
       "44             0                5                         6\n",
       "45             4                4                         2\n",
       "46             6                2                         0\n",
       "47             1                0                         3\n",
       "48             2                2                         4\n",
       "49             1                5                         5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              predictedvalues\n",
       "actualvalues                 \n",
       "0                          12\n",
       "1                          17\n",
       "2                           8\n",
       "3                          10\n",
       "4                          23\n",
       "5                          11\n",
       "6                          15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "0                          20\n",
       "1                           5\n",
       "2                           6\n",
       "3                           6\n",
       "4                          39\n",
       "5                          13\n",
       "6                           7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16, channels=1, rate=44100, input=True, frames_per_buffer=1024)\n",
    "print(\"* recording\")\n",
    "frames = []\n",
    "for i in range(0, int(44100 / 1024 * 4)):\n",
    "    data = stream.read(1024)\n",
    "    frames.append(data)\n",
    "print(\"* done recording\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(\"output.wav\", 'wb')\n",
    "wf.setnchannels(1)\n",
    "wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "wf.setframerate(44100)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = []\n",
    "mfcc_len=39\n",
    "max_fs = 0\n",
    "min_sample = int('9' * 10)\n",
    "s = 0\n",
    "cnt = 0\n",
    "fs, signal = read_wav(\"output.wav\")\n",
    "fs1, signal1 = read_wav(\"1.wav\")\n",
    "max_fs = max(max_fs, fs)\n",
    "s_len = len(signal)\n",
    "if s_len < mslen:\n",
    "    pad_len = mslen - s_len\n",
    "    pad_rem = pad_len % 2\n",
    "    pad_len /= 2\n",
    "    signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "else:\n",
    "    pad_len = s_len - mslen\n",
    "    pad_rem = pad_len % 2\n",
    "    pad_len /= 2\n",
    "    signal = signal[int(pad_len):int(pad_len) + mslen]\n",
    "min_sample = min(len(signal), min_sample)\n",
    "mfcc = speechpy.feature.mfcc(signal, fs, num_cepstral=mfcc_len)\n",
    "\n",
    "mfcc = mfcc.flatten()\n",
    "testdata.append(mfcc)\n",
    "testdata = testdata[0][0:2730]\n",
    "xshape = (70, 39)\n",
    "testdata = np.array(testdata)\n",
    "testdata = testdata.reshape(xshape)\n",
    "listk = np.array(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 39)\n"
     ]
    }
   ],
   "source": [
    "in_shape1 = listk.shape\n",
    "print(in_shape1)\n",
    "testdata = testdata.reshape(1, in_shape1[0], in_shape1[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally = model.predict(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02342437 0.47165182 0.06639561 0.02513868 0.40918267 0.00063977\n",
      "  0.0035672 ]]\n"
     ]
    }
   ],
   "source": [
    "print((tally))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
